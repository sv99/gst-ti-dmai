/*
 * gsttidmaienc.c
 *
 * This file defines the a generic encoder element based on DMAI
 *
 * Original Author:
 *     Don Darling, Texas Instruments, Inc.
 *
 * Code Refactoring by:
 *     Diego Dompe, RidgeRun
 *
 * Contributor:
 *     Cristina Murillo, RidgeRun
 *     Kapil Agrawal, RidgeRun
 *
 * Copyright (C) $year Texas Instruments Incorporated - http://www.ti.com/
 * Copyright (C) 2009 RidgeRun
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU Lesser General Public License as
 * published by the Free Software Foundation version 2.1 of the License.
 *
 * This program is distributed #as is# WITHOUT ANY WARRANTY of any kind,
 * whether express or implied; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 */

/*
 * TODO LIST
 *
 * - Speech encoding
 */

#ifdef HAVE_CONFIG_H
#  include <config.h>
#endif

#include <stdio.h>
#include <string.h>
#include <sched.h>
#include <gst/gst.h>

#include <ti/sdo/dmai/Dmai.h>
#include <ti/sdo/dmai/Buffer.h>
#include <ti/sdo/dmai/BufferGfx.h>
#include <ti/sdo/dmai/BufTab.h>
#include <ti/xdais/dm/xdm.h>
#include <ti/xdais/dm/ivideo.h>

#include "gsttidmaienc.h"
#include "gsttidmaibuffertransport.h"
#include "gstticommonutils.h"

/* Declare variable used to categorize GST_LOG output */
GST_DEBUG_CATEGORY (gst_tidmaienc_debug);
#define GST_CAT_DEFAULT gst_tidmaienc_debug

/* Element property identifiers */
enum
{
    PROP_0,
    PROP_SIZE_OUTPUT_BUF, /* sizeOutputBuf  (int)     */
    PROP_COPY_OUTPUT,     /* copyOutput    (boolean) */
};

/* Declare a global pointer to our element base class */
static GstElementClass *parent_class = NULL;

/* Static Function Declarations */
static void
 gst_tidmaienc_base_init(GstTIDmaiencClass *klass);
static void
 gst_tidmaienc_class_init(GstTIDmaiencClass *g_class);
static void
 gst_tidmaienc_init(GstTIDmaienc *object, GstTIDmaiencClass *g_class);
static void
 gst_tidmaienc_set_property (GObject *object, guint prop_id,
    const GValue *value, GParamSpec *pspec);
static void
 gst_tidmaienc_get_property (GObject *object, guint prop_id, GValue *value,
    GParamSpec *pspec);
static gboolean
 gst_tidmaienc_set_sink_caps(GstPad *pad, GstCaps *caps);
static gboolean
 gst_tidmaienc_sink_event(GstPad *pad, GstEvent *event);
static GstFlowReturn
 gst_tidmaienc_chain(GstPad *pad, GstBuffer *buf);
static GstStateChangeReturn
 gst_tidmaienc_change_state(GstElement *element, GstStateChange transition);
static gboolean
 gst_tidmaienc_init_encoder(GstTIDmaienc *dmaienc);
static gboolean
 gst_tidmaienc_exit_encoder(GstTIDmaienc *dmaienc);
static gboolean
 gst_tidmaienc_configure_codec (GstTIDmaienc *dmaienc);
static gboolean
 gst_tidmaienc_deconfigure_codec (GstTIDmaienc *dmaienc);
static int
 encode(GstTIDmaienc *dmaienc,GstBuffer * buf);

/*
 * Register all the required encoders
 * Receives a NULL terminated array of encoder instances.
 */
gboolean register_dmai_encoder(GstPlugin * plugin, GstTIDmaiencData *encoder){
    GTypeInfo typeinfo = {
           sizeof(GstTIDmaiencClass),
           (GBaseInitFunc)gst_tidmaienc_base_init,
           NULL,
           (GClassInitFunc)gst_tidmaienc_class_init,
           NULL,
           NULL,
           sizeof(GstTIDmaienc),
           0,
           (GInstanceInitFunc) gst_tidmaienc_init
       };
    GType type;
    gchar *type_name;

    /* Initialize GST_LOG for this object */
    GST_DEBUG_CATEGORY_INIT(gst_tidmaienc_debug, "TIDmaienc", 0,
        "DMAI VISA Encoder");

    type_name = g_strdup_printf ("dmaienc_%s", encoder->streamtype);

    /* Check if it exists */
    if (g_type_from_name (type_name)) {
        g_free (type_name);
        g_warning("Not creating type %s, since it exists already",type_name);
        return FALSE;
    }

    type = g_type_register_static (GST_TYPE_ELEMENT, type_name, &typeinfo, 0);
    g_type_set_qdata (type, GST_TIDMAIENC_PARAMS_QDATA, (gpointer) encoder);

    if (!gst_element_register(plugin, type_name, GST_RANK_PRIMARY,type)) {
          g_warning ("Failed to register %s", type_name);
          g_free (type_name);
          return FALSE;
    }

    GST_DEBUG("DMAI encoder %s registered\n",type_name);
    g_free(type_name);

    return TRUE;
}

/******************************************************************************
 * gst_tidmaienc_base_init
 *    Boiler-plate function auto-generated by "make_element" script.
 *    Initializes element base class.
 ******************************************************************************/
static void gst_tidmaienc_base_init(GstTIDmaiencClass *klass)
{
    GstElementClass *element_class = GST_ELEMENT_CLASS(klass);
    GstTIDmaiencData *encoder;
    static GstElementDetails details;
    gchar *codec_type, *codec_name;
    GstCaps *srccaps, *sinkcaps;
    GstPadTemplate *sinktempl, *srctempl;
    struct codec_custom_data_entry *data_entry = codec_custom_data;

    encoder = (GstTIDmaiencData *)
     g_type_get_qdata(G_OBJECT_CLASS_TYPE(klass),GST_TIDMAIENC_PARAMS_QDATA);
    g_assert (encoder != NULL);
    g_assert (encoder->streamtype != NULL);
    g_assert (encoder->srcCaps != NULL);
    g_assert (encoder->sinkCaps != NULL);
    g_assert (encoder->eops != NULL);
    g_assert (encoder->eops->codec_type != 0);

    switch (encoder->eops->codec_type){
    case VIDEO:
        codec_type = g_strdup("Video");
        break;
    case AUDIO:
        codec_type = g_strdup("Audio");
        break;
    case IMAGE:
        codec_type = g_strdup("Image");
        break;
    default:
        g_warning("Unkown encoder codec type");
        return;
    }

    codec_name = g_ascii_strup(encoder->streamtype,strlen(encoder->streamtype));
    details.longname = g_strdup_printf ("DMAI %s %s Encoder",
                            encoder->eops->xdmversion,
                            codec_name);
    details.klass = g_strdup_printf ("Codec/Encoder/%s",codec_type);
    details.description = g_strdup_printf ("DMAI %s encoder",codec_name);
      details.author = "Don Darling; Texas Instruments, Inc., "
                       "Diego Dompe; RidgeRun Engineering ";

    g_free(codec_type);
    g_free(codec_name);

    /* Search for custom codec data */
    klass->codec_data = NULL;
    while (data_entry->codec_name != NULL){
        if (!strcmp(data_entry->codec_name,encoder->codecName)){
            klass->codec_data = &data_entry->data;
            GST_INFO("Got custom codec data for instance of %s",encoder->codecName);
            break;
        }
        data_entry++;
    }

    /* pad templates */
    if (klass->codec_data && klass->codec_data->sinkCaps) {
        sinkcaps = gst_static_caps_get(klass->codec_data->sinkCaps);
    } else {
        sinkcaps = gst_static_caps_get(encoder->sinkCaps);
    }
    sinktempl = gst_pad_template_new ("sink", GST_PAD_SINK, GST_PAD_ALWAYS,
        sinkcaps);

    if (klass->codec_data && klass->codec_data->srcCaps) {
        srccaps = gst_static_caps_get(klass->codec_data->srcCaps);
    } else {
        srccaps = gst_static_caps_get(encoder->srcCaps);
    }
    srctempl = gst_pad_template_new ("src", GST_PAD_SRC, GST_PAD_ALWAYS,
        srccaps);

    gst_element_class_add_pad_template(element_class,srctempl);
    gst_element_class_add_pad_template(element_class,sinktempl);
    gst_element_class_set_details(element_class, &details);

    klass->srcTemplateCaps = srctempl;
    klass->sinkTemplateCaps = sinktempl;
}


/******************************************************************************
 * gst_tidmaienc_finalize
 *****************************************************************************/
static void gst_tidmaienc_finalize(GObject * object)
{
    GstTIDmaienc *dmaienc = (GstTIDmaienc *)object;

    if (dmaienc->params){
        g_free(dmaienc->params);
        dmaienc->params = NULL;
    }
    if (dmaienc->dynParams){
        g_free(dmaienc->dynParams);
        dmaienc->dynParams = NULL;
    }
    if (dmaienc->stream_private){
        g_free(dmaienc->stream_private);
    }

    G_OBJECT_CLASS(g_type_class_peek_parent(G_OBJECT_GET_CLASS (object)))
        ->finalize (object);
}

/******************************************************************************
 * gst_tidmaienc_class_init
 *    Boiler-plate function auto-generated by "make_element" script.
 *    Initializes the TIDmaienc class.
 ******************************************************************************/
static void gst_tidmaienc_class_init(GstTIDmaiencClass *klass)
{
    GObjectClass    *gobject_class;
    GstElementClass *gstelement_class;
    GstTIDmaiencData *encoder;

    gobject_class    = (GObjectClass*)    klass;
    gstelement_class = (GstElementClass*) klass;
    encoder = (GstTIDmaiencData *)
      g_type_get_qdata(G_OBJECT_CLASS_TYPE(klass),GST_TIDMAIENC_PARAMS_QDATA);
    g_assert (encoder != NULL);
    g_assert (encoder->codecName != NULL);
    g_assert (encoder->engineName != NULL);

    parent_class = g_type_class_peek_parent(klass);

    gobject_class->set_property = gst_tidmaienc_set_property;
    gobject_class->get_property = gst_tidmaienc_get_property;
    gobject_class->finalize = GST_DEBUG_FUNCPTR(gst_tidmaienc_finalize);

    gstelement_class->change_state = gst_tidmaienc_change_state;

    g_object_class_install_property(gobject_class, PROP_SIZE_OUTPUT_BUF,
        g_param_spec_int("outputBufferSize",
            "Size of the output buffer",
            "Size of the output buffer",
            0, G_MAXINT32, 0, G_PARAM_READWRITE));

    g_object_class_install_property(gobject_class, PROP_COPY_OUTPUT,
        g_param_spec_boolean("copyOutput",
            "Copy the output buffers",
            "Boolean that set if the output buffers should be copied into standard gst buffers",
            FALSE, G_PARAM_READWRITE));

    /* Install custom properties for this codec type */
    if (encoder->eops->install_properties){
        encoder->eops->install_properties(gobject_class);
    }

    /* Install custom properties for this stream type */
    if (encoder->stream_ops && encoder->stream_ops->install_properties){
        encoder->stream_ops->install_properties(gobject_class);
    }
    /* If this codec provide custom properties... */
    if (klass->codec_data && klass->codec_data->install_properties) {
        GST_DEBUG("Installing custom properties for %s",encoder->codecName);
        klass->codec_data->install_properties(gobject_class);
    }
}

/******************************************************************************
 * gst_tidmaienc_init
 *    Initializes a new element instance, instantiates pads and sets the pad
 *    callback functions.
 ******************************************************************************/
static void gst_tidmaienc_init(GstTIDmaienc *dmaienc, GstTIDmaiencClass *gclass)
{
    GstTIDmaiencData *encoder;

    encoder = (GstTIDmaiencData *)
      g_type_get_qdata(G_OBJECT_CLASS_TYPE(gclass),GST_TIDMAIENC_PARAMS_QDATA);

    /* Initialize the rest of the codec */
    if (gclass->codec_data && gclass->codec_data->setup_params) {
        /* If our specific codec provides custom parameters... */
        GST_DEBUG("Use custom setup params");
        gclass->codec_data->setup_params(GST_ELEMENT(dmaienc));
    } else {
        /* Otherwise just use the default encoder implementation */
        GST_DEBUG("Use default setup params");
        encoder->eops->default_setup_params(dmaienc);
    }

    /* Allow the streamer to allocate any private data it may require */
    if (encoder->stream_ops && encoder->stream_ops->setup){
        encoder->stream_ops->setup(dmaienc);
    }

    /* Identify our keyframe type based in our stream type */
    if (!strcmp(encoder->streamtype,"h264")) {
        dmaienc->keyFrameType = IVIDEO_IDR_FRAME;
    } else {
        dmaienc->keyFrameType = IVIDEO_I_FRAME;
    }

    /* Instantiate raw sink pad.
     *
     * Fixate on our static template caps instead of writing a getcaps
     * function, which is overkill for this element.
     */
    dmaienc->sinkpad =
        gst_pad_new_from_template(gclass->sinkTemplateCaps, "sink");
    gst_pad_set_setcaps_function(
        dmaienc->sinkpad, GST_DEBUG_FUNCPTR(gst_tidmaienc_set_sink_caps));
    gst_pad_set_event_function(
        dmaienc->sinkpad, GST_DEBUG_FUNCPTR(gst_tidmaienc_sink_event));
    gst_pad_set_chain_function(
        dmaienc->sinkpad, GST_DEBUG_FUNCPTR(gst_tidmaienc_chain));

    /* Instantiate encoded source pad.
     *
     * Fixate on our static template caps instead of writing a getcaps
     * function, which is overkill for this element.
     */
    dmaienc->srcpad =
        gst_pad_new_from_template(gclass->srcTemplateCaps, "src");

    /* Add pads to TIDmaienc element */
    gst_element_add_pad(GST_ELEMENT(dmaienc), dmaienc->sinkpad);
    gst_element_add_pad(GST_ELEMENT(dmaienc), dmaienc->srcpad);

    /* Initialize TIDmaienc state */
    dmaienc->engineName         = g_strdup(encoder->engineName);
    dmaienc->codecName          = g_strdup(encoder->codecName);

    dmaienc->hEngine            = NULL;
    dmaienc->hCodec             = NULL;
    dmaienc->copyOutput         = FALSE;

    dmaienc->adapter            = NULL;

    dmaienc->freeSlices         = NULL;

    dmaienc->outBuf             = NULL;
    dmaienc->inBuf              = NULL;
    dmaienc->inBufSize          = 0;
    dmaienc->singleOutBufSize   = 0;
    dmaienc->outBufSize         = 0;

    /* Initialize TIDmaienc video state */

    dmaienc->framerateNum       = 0;
    dmaienc->framerateDen       = 0;
    dmaienc->height	            = 0;
    dmaienc->width	            = 0;
    dmaienc->par_n = 1;
    dmaienc->par_d = 1;

    /*Initialize TIDmaienc audio state */

    dmaienc->channels           = 0;
    dmaienc->depth              = 0;
    dmaienc->awidth             = 0;
    dmaienc->rate               = 0;

    dmaienc->asampleSize        = GST_CLOCK_TIME_NONE;
    dmaienc->asampleTime        = GST_CLOCK_TIME_NONE;
}


/******************************************************************************
 * gst_tidmaienc_set_property
 *     Set element properties when requested.
 ******************************************************************************/
static void gst_tidmaienc_set_property(GObject *object, guint prop_id,
    const GValue *value, GParamSpec *pspec)
{
    GstTIDmaienc *dmaienc = (GstTIDmaienc *)object;
    GstTIDmaiencClass      *klass =
        (GstTIDmaiencClass *) (G_OBJECT_GET_CLASS (dmaienc));
    GstTIDmaiencData *encoder = (GstTIDmaiencData *)
      g_type_get_qdata(G_OBJECT_CLASS_TYPE(klass),GST_TIDMAIENC_PARAMS_QDATA);

    GST_LOG("begin set_property\n");

    switch (prop_id) {
    case PROP_SIZE_OUTPUT_BUF:
        dmaienc->outBufSize = g_value_get_int(value);
        GST_LOG("setting \"outBufSize\" to \"%d\"\n",
            dmaienc->outBufSize);
        break;
    case PROP_COPY_OUTPUT:
        dmaienc->copyOutput = g_value_get_boolean(value);
        GST_LOG("seeting \"copyOutput\" to %s\n",
            dmaienc->copyOutput?"TRUE":"FALSE");
        break;
    default:
        /* If this codec provide custom properties...
         * We allow custom codecs to overwrite the generic properties
         */
        if (klass->codec_data && klass->codec_data->set_property) {
            klass->codec_data->set_property(object,prop_id,value,pspec);
        }
        if (encoder->eops->set_property){
            encoder->eops->set_property(object,prop_id,value,pspec);
        }
        if (encoder->stream_ops && encoder->stream_ops->set_property){
            encoder->stream_ops->set_property(object,prop_id,value,pspec);
        }
        break;
    }

    GST_LOG("end set_property\n");
}

/******************************************************************************
 * gst_tidmaienc_get_property
 *     Return values for requested element property.
 ******************************************************************************/
static void gst_tidmaienc_get_property(GObject *object, guint prop_id,
    GValue *value, GParamSpec *pspec)
{
    GstTIDmaienc *dmaienc = (GstTIDmaienc *)object;
    GstTIDmaiencClass      *klass =
        (GstTIDmaiencClass *) (G_OBJECT_GET_CLASS (dmaienc));
    GstTIDmaiencData *encoder = (GstTIDmaiencData *)
      g_type_get_qdata(G_OBJECT_CLASS_TYPE(klass),GST_TIDMAIENC_PARAMS_QDATA);

    GST_LOG("begin get_property\n");

    switch (prop_id) {
    case PROP_SIZE_OUTPUT_BUF:
        g_value_set_int(value,dmaienc->outBufSize);
        break;
    case PROP_COPY_OUTPUT:
        g_value_set_boolean(value,dmaienc->copyOutput);
        break;
    default:
        /* If this codec provide custom properties...
         * We allow custom codecs to overwrite the generic properties
         */
        if (klass->codec_data && klass->codec_data->get_property) {
            klass->codec_data->get_property(object,prop_id,value,pspec);
        }
        if (encoder->eops->get_property){
            encoder->eops->get_property(object,prop_id,value,pspec);
        }
        if (encoder->stream_ops && encoder->stream_ops->get_property){
            encoder->stream_ops->get_property(object,prop_id,value,pspec);
        }
        break;
    }

    GST_LOG("end get_property\n");
}


/******************************************************************************
 * gst_tidmaienc_change_state
 *     Manage state changes for the video stream.  The gStreamer documentation
 *     states that state changes must be handled in this manner:
 *        1) Handle ramp-up states
 *        2) Pass state change to base class
 *        3) Handle ramp-down states
 ******************************************************************************/
static GstStateChangeReturn gst_tidmaienc_change_state(GstElement *element,
    GstStateChange transition)
{
    GstStateChangeReturn  ret    = GST_STATE_CHANGE_SUCCESS;
    GstTIDmaienc          *dmaienc = (GstTIDmaienc *)element;

    GST_DEBUG("begin change_state (%d)\n", transition);

    /* Handle ramp-up state changes */
    switch (transition) {
    case GST_STATE_CHANGE_NULL_TO_READY:
        /* Init encoder */
        GST_DEBUG("GST_STATE_CHANGE_NULL_TO_READY");
        if (!gst_tidmaienc_init_encoder(dmaienc)) {
            return GST_STATE_CHANGE_FAILURE;
        }
        break;
    default:
        break;
    }

    /* Pass state changes to base class */
    ret = GST_ELEMENT_CLASS(parent_class)->change_state(element, transition);
    if (ret == GST_STATE_CHANGE_FAILURE)
        return ret;

    /* Handle ramp-down state changes */
    switch (transition) {
    case GST_STATE_CHANGE_PAUSED_TO_READY:
        GST_DEBUG("GST_STATE_CHANGE_READY_TO_NULL");
        /* Deconfigure the encoder */
        if (!gst_tidmaienc_deconfigure_codec(dmaienc)) {
            GST_ELEMENT_ERROR(dmaienc,STREAM,FAILED,(NULL),
                ("Failed to deconfigure codec"));
            return GST_STATE_CHANGE_FAILURE;
        }
        break;
    case GST_STATE_CHANGE_READY_TO_NULL:
        GST_DEBUG("GST_STATE_CHANGE_READY_TO_NULL");
        /* Shut down encoder */
        if (!gst_tidmaienc_exit_encoder(dmaienc)) {
            GST_ELEMENT_ERROR(dmaienc,STREAM,FAILED,(NULL),
                ("Failed to destroy codec"));
            return GST_STATE_CHANGE_FAILURE;
        }
        break;
    default:
        break;
    }

    GST_DEBUG("end change_state\n");
    return ret;
}


/******************************************************************************
 * gst_tidmaienc_init_encoder
 *     Initialize or re-initializes the stream
 ******************************************************************************/
static gboolean gst_tidmaienc_init_encoder(GstTIDmaienc *dmaienc)
{
    GstTIDmaiencClass *gclass;
    GstTIDmaiencData *encoder;

    gclass = (GstTIDmaiencClass *) (G_OBJECT_GET_CLASS (dmaienc));
    encoder = (GstTIDmaiencData *)
        g_type_get_qdata(G_OBJECT_CLASS_TYPE(gclass),GST_TIDMAIENC_PARAMS_QDATA);

    GST_DEBUG("begin init_encoder\n");

    /* Make sure we know what codec we're using */
    if (!dmaienc->engineName) {
        GST_ELEMENT_ERROR(dmaienc,STREAM,CODEC_NOT_FOUND,(NULL),
            ("Engine name not specified"));
        return FALSE;
    }

    if (!dmaienc->codecName) {
        GST_ELEMENT_ERROR(dmaienc,STREAM,CODEC_NOT_FOUND,(NULL),
            ("Codec name not specified"));
        return FALSE;
    }

    /* Open the codec engine */
    GST_DEBUG("opening codec engine \"%s\"\n", dmaienc->engineName);
    dmaienc->hEngine = Engine_open((Char *) dmaienc->engineName, NULL, NULL);

    if (dmaienc->hEngine == NULL) {
        GST_ELEMENT_ERROR(dmaienc,STREAM,CODEC_NOT_FOUND,(NULL),
            ("failed to open codec engine \"%s\"", dmaienc->engineName));
        return FALSE;
    }

    dmaienc->adapter = gst_adapter_new();
    if (!dmaienc->adapter){
        GST_ELEMENT_ERROR(dmaienc,RESOURCE,NO_SPACE_LEFT,(NULL),
            ("failed to create adapter"));
        gst_tidmaienc_exit_encoder(dmaienc);
        return FALSE;
    }

    /* Status variables */
    dmaienc->basets = GST_CLOCK_TIME_NONE;
    dmaienc->freeSlices = NULL;

    GST_DEBUG("end init_encoder\n");
    return TRUE;
}


/******************************************************************************
 * gst_tidmaienc_exit_encoder
 *    Shut down any running video encoder, and reset the element state.
 ******************************************************************************/
static gboolean gst_tidmaienc_exit_encoder(GstTIDmaienc *dmaienc)
{
    GstTIDmaiencClass *gclass;
    GstTIDmaiencData *encoder;

    gclass = (GstTIDmaiencClass *) (G_OBJECT_GET_CLASS (dmaienc));
    encoder = (GstTIDmaiencData *)
       g_type_get_qdata(G_OBJECT_CLASS_TYPE(gclass),GST_TIDMAIENC_PARAMS_QDATA);

    GST_DEBUG("begin exit_encoder\n");

    if (dmaienc->adapter){
        gst_adapter_clear(dmaienc->adapter);
        gst_object_unref(dmaienc->adapter);
        dmaienc->adapter = NULL;
    }

    if (dmaienc->hEngine) {
        GST_DEBUG("closing codec engine\n");
        Engine_close(dmaienc->hEngine);
        dmaienc->hEngine = NULL;
    }

    GST_DEBUG("end exit_encoder\n");
    return TRUE;
}

/******************************************************************************
 * gst_tidmaienc_configure_codec
 *     Initialize codec engine
 *****************************************************************************/
static gboolean gst_tidmaienc_configure_codec (GstTIDmaienc  *dmaienc)
{
    Buffer_Attrs           Attrs     = Buffer_Attrs_DEFAULT;
    GstTIDmaiencClass      *gclass;
    GstTIDmaiencData       *encoder;
    struct cmemSlice *slice;

    gclass = (GstTIDmaiencClass *) (G_OBJECT_GET_CLASS (dmaienc));
    encoder = (GstTIDmaiencData *)
       g_type_get_qdata(G_OBJECT_CLASS_TYPE(gclass),GST_TIDMAIENC_PARAMS_QDATA);

    GST_DEBUG("Init\n");

    /* We create the codec here since only at this point we got the custom args */
    if (!encoder->eops->codec_create(dmaienc)) {
        return FALSE;
    }

    dmaienc->firstBuffer = TRUE;

    if (!dmaienc->singleOutBufSize){
        dmaienc->singleOutBufSize = encoder->eops->codec_get_outBufSize(dmaienc);
    }
    if (!dmaienc->inBufSize){
        dmaienc->inBufSize = encoder->eops->codec_get_inBufSize(dmaienc);
    }

    Attrs.useMask = gst_tidmaibuffertransport_GST_FREE;

    if (dmaienc->outBufSize == 0) {
        dmaienc->outBufSize = dmaienc->singleOutBufSize * 3;
    }

    slice = g_malloc0(sizeof(struct cmemSlice));
    slice->start = 0;
    slice->end = dmaienc->outBufSize;
    slice->size = dmaienc->outBufSize;
    dmaienc->freeMutex = g_mutex_new();
    dmaienc->freeSlices = g_list_append(dmaienc->freeSlices,slice);

    GST_DEBUG("Output bufer size %d, Input buffer size %d\n",dmaienc->outBufSize,dmaienc->inBufSize);

    /* Create codec output buffers */
    GST_DEBUG("creating output buffer \n");
    dmaienc->outBuf = Buffer_create(dmaienc->outBufSize, &Attrs);

    if (dmaienc->outBuf == NULL) {
        GST_ELEMENT_ERROR(dmaienc,RESOURCE,NO_SPACE_LEFT,(NULL),
            ("failed to create output buffers"));
        return FALSE;
    }
    GST_DEBUG("Output buffer handler: %p\n",dmaienc->outBuf);

    return TRUE;
}



/******************************************************************************
 * gst_tidmaienc_deconfigure_codec
 *     free codec engine resources
 *****************************************************************************/
static gboolean gst_tidmaienc_deconfigure_codec (GstTIDmaienc  *dmaienc)
{
    GstTIDmaiencClass      *gclass;
    GstTIDmaiencData       *encoder;

    gclass = (GstTIDmaiencClass *) (G_OBJECT_GET_CLASS (dmaienc));
    encoder = (GstTIDmaiencData *)
       g_type_get_qdata(G_OBJECT_CLASS_TYPE(gclass),GST_TIDMAIENC_PARAMS_QDATA);

    /* Wait for free all downstream buffers */
    if (dmaienc->freeSlices &&
        ((struct cmemSlice *)(dmaienc->freeSlices->data))->size != dmaienc->outBufSize){
        GST_ELEMENT_WARNING(dmaienc,RESOURCE,NO_SPACE_LEFT,(NULL),
            ("Not all downstream buffers are free... forcing release, this may cause a segfault\n"));
    }
    if (dmaienc->freeSlices){
        g_mutex_lock(dmaienc->freeMutex);
        GList *e = dmaienc->freeSlices;

        /* Merge free memory */
        while (e){
            g_free(e->data);
            e = g_list_next(e);
        }
        g_list_free(dmaienc->freeSlices);
        
        dmaienc->freeSlices = NULL;
        g_mutex_unlock(dmaienc->freeMutex);
        g_mutex_free(dmaienc->freeMutex);
    }

    if (dmaienc->outBuf) {
        GST_DEBUG("freeing output buffer, %p\n",dmaienc->outBuf);
        Buffer_delete(dmaienc->outBuf);
        dmaienc->outBuf = NULL;
    }

    if (dmaienc->inBuf){
        GST_DEBUG("freeing input buffer, %p\n",dmaienc->inBuf);
        Buffer_delete(dmaienc->inBuf);
        dmaienc->inBuf = NULL;
    }

    if (dmaienc->hCodec) {
        GST_LOG("closing video encoder\n");
        encoder->eops->codec_destroy(dmaienc);
        dmaienc->hCodec = NULL;
    }
    return TRUE;
}


/******************************************************************************
 * gst_tidmaienc_set_sink_caps
 *     Negotiate our sink pad capabilities.
 ******************************************************************************/
static gboolean gst_tidmaienc_set_sink_caps(GstPad *pad, GstCaps *caps)
{
    GstTIDmaienc *dmaienc;
    GstStructure *capStruct;
    const gchar  *mime;
    char * str = NULL;
    guint32 fourcc;
    GstCaps *othercaps, *newcaps = NULL;
    GstTIDmaiencClass *gclass;
    GstTIDmaiencData *encoder;

    dmaienc =(GstTIDmaienc *) gst_pad_get_parent(pad);
    gclass = (GstTIDmaiencClass *) (G_OBJECT_GET_CLASS (dmaienc));
    encoder = (GstTIDmaiencData *)
      g_type_get_qdata(G_OBJECT_CLASS_TYPE(gclass),GST_TIDMAIENC_PARAMS_QDATA);

    capStruct = gst_caps_get_structure(caps, 0);
    mime      = gst_structure_get_name(capStruct);

    GST_INFO("requested sink caps:  %s", gst_caps_to_string(caps));

    /* Generic Video Properties */
    if (!strncmp(mime, "video/", 6) ||
        !strncmp(mime, "image/", 6)) {
        gint framerateNum;
        gint framerateDen;

        if (gst_structure_get_fraction(capStruct, "framerate", &framerateNum,
            &framerateDen)) {
            dmaienc->framerateNum = framerateNum;
            dmaienc->framerateDen = framerateDen;
            dmaienc->averageDuration = (framerateDen * 1000000000ll) / (long long)framerateNum;
        } else {
            dmaienc->averageDuration = GST_CLOCK_TIME_NONE;
        }

        if (!gst_structure_get_fraction(capStruct, "pixel-aspect-ratio", &dmaienc->par_n, &dmaienc->par_d)) {
            dmaienc->par_n = 1;
            dmaienc->par_d = 1;
        }

        if (!gst_structure_get_int(capStruct, "height", &dmaienc->height)) {
            dmaienc->height = 0;
        }

        if (!gst_structure_get_int(capStruct, "width", &dmaienc->width)) {
            dmaienc->width = 0;
        }

        if (!gst_structure_get_int(capStruct, "pitch", &dmaienc->pitch)) {
            dmaienc->pitch = 0;
        }

        if (gst_structure_get_fourcc(capStruct, "format", &fourcc)) {

            switch (fourcc) {
                case GST_MAKE_FOURCC('U', 'Y', 'V', 'Y'):
                    dmaienc->colorSpace = ColorSpace_UYVY;
                    break;
                case GST_MAKE_FOURCC('Y', '8', 'C', '8'):
                    dmaienc->colorSpace = ColorSpace_YUV422PSEMI;
                    break;
                case GST_MAKE_FOURCC('N', 'V', '1', '2'):
                    dmaienc->colorSpace = ColorSpace_YUV420PSEMI;
                    break;
                default:
                    GST_ELEMENT_ERROR(dmaienc, STREAM, NOT_IMPLEMENTED,
                        ("unsupported fourcc in video stream\n"), (NULL));
                    gst_object_unref(dmaienc);
                    return FALSE;
            }
        }

        /* Pick the output caps */
        othercaps = gst_pad_get_allowed_caps (dmaienc->srcpad);
        newcaps = gst_caps_copy_nth (othercaps, 0);
        gst_caps_unref(othercaps);

        capStruct = gst_caps_get_structure(newcaps, 0);
        gst_structure_set(capStruct,"height",G_TYPE_INT,dmaienc->height,
                                    "width",G_TYPE_INT,dmaienc->width,
                                    "framerate", GST_TYPE_FRACTION,
                                        dmaienc->framerateNum,dmaienc->framerateDen,
                                    "pixel-aspect-ratio", GST_TYPE_FRACTION, 
                                    dmaienc->par_n, dmaienc->par_d,
                                    (char *)NULL);

        dmaienc->inBufSize = gst_ti_calculate_bufSize (
            dmaienc->width,dmaienc->height,dmaienc->colorSpace);
        /* We need to ask the codec for the outbuffer size, even if we could
         * guess a safe value, some encoders may have their own ideas...
         */
        dmaienc->singleOutBufSize = 0;
    } else if(!strncmp(mime, "audio/", 6)){
        /* Generic Audio Properties */

        if (!gst_structure_get_int(capStruct, "channels", &dmaienc->channels)){
            dmaienc->channels = 0;
        }

        if (!gst_structure_get_int(capStruct, "width", &dmaienc->awidth)){
            dmaienc->awidth = 0;
        }

        if (!gst_structure_get_int(capStruct, "depth", &dmaienc->depth)){
            dmaienc->depth = 0;
        }

        if (!gst_structure_get_int(capStruct, "rate", &dmaienc->rate)){
            dmaienc->rate = 0;
        }

        /* Pick the output caps */
        othercaps = gst_pad_get_allowed_caps (dmaienc->srcpad);
        newcaps = gst_caps_copy_nth (othercaps, 0);
        gst_caps_unref(othercaps);

        /* gst_pad_get_pad_template_caps: gets the capabilities of
         * dmaienc->srcpad, then creates a copy and makes it writable
         */
        capStruct = gst_caps_get_structure(newcaps, 0);

        gst_structure_set(capStruct,"channels",G_TYPE_INT,dmaienc->channels,
                                    "rate",G_TYPE_INT,dmaienc->rate,
                                    (char *)NULL);

        /* Calculate some properties */
        dmaienc->asampleSize = (dmaienc->awidth >> 3) * dmaienc->channels;
        dmaienc->asampleTime = 1000000000l / dmaienc->rate;

        /* Ask the codec for the input and output buffer size */
        dmaienc->inBufSize = 0;
        dmaienc->singleOutBufSize = 0;

        if (gclass->codec_data && gclass->codec_data->max_samples) {
               dmaienc->inBufSize = gclass->codec_data->max_samples *
                   (dmaienc->awidth >> 3) * dmaienc->channels;
               GST_DEBUG("Codec can process at most %d samples per call",
                   gclass->codec_data->max_samples);
        }
    }

    if (!newcaps){
        GST_ELEMENT_ERROR(dmaienc,STREAM,FAILED,(NULL),
            ("Failed to calculate the srcpad caps"));
        gst_object_unref(dmaienc);
        return FALSE;
    }
    
    GST_DEBUG("Setting source caps: '%s'", (str = gst_caps_to_string(newcaps)));
    g_free(str);

    if (!gst_pad_set_caps(dmaienc->srcpad, newcaps)) {
        GST_ELEMENT_ERROR(dmaienc,STREAM,FAILED,(NULL),
           	("Failed to set the srcpad caps"));
    } else {
	    /* Set the caps on the parameters of the encoder */
	    encoder->eops->set_codec_caps(dmaienc);

	    if (gclass->codec_data && gclass->codec_data->set_codec_caps) {
	    	gclass->codec_data->set_codec_caps((GstElement*)dmaienc);
	    }

	    if (!gst_tidmaienc_deconfigure_codec(dmaienc)) {
	        gst_object_unref(dmaienc);
	        GST_ELEMENT_ERROR(dmaienc,STREAM,FAILED,(NULL),
    	       	("Failed to deconfigure codec"));
	        return FALSE;
	    }

        if (!gst_tidmaienc_configure_codec(dmaienc)) {
            GST_ELEMENT_ERROR(dmaienc,STREAM,FAILED,(NULL),
                ("Failed to configure codec"));
            gst_caps_unref(newcaps);
            gst_object_unref(dmaienc);
            return FALSE;
        }

        GST_DEBUG("sink caps negotiation successful\n");
    }
    gst_caps_unref(newcaps);
    gst_object_unref(dmaienc);

    return TRUE;
}


/******************************************************************************
 * gst_tidmaienc_sink_event
 *     Perform event processing.
 ******************************************************************************/
static gboolean gst_tidmaienc_sink_event(GstPad *pad, GstEvent *event)
{
    GstTIDmaienc *dmaienc;
    gboolean      ret = FALSE;
    GstTIDmaiencClass *gclass;
    GstTIDmaiencData *encoder;

    dmaienc =(GstTIDmaienc *) gst_pad_get_parent(pad);
    gclass = (GstTIDmaiencClass *) (G_OBJECT_GET_CLASS (dmaienc));
    encoder = (GstTIDmaiencData *)
      g_type_get_qdata(G_OBJECT_CLASS_TYPE(gclass),GST_TIDMAIENC_PARAMS_QDATA);

    GST_DEBUG("pad \"%s\" received:  %s\n", GST_PAD_NAME(pad),
        GST_EVENT_TYPE_NAME(event));

    switch (GST_EVENT_TYPE(event)) {
    case GST_EVENT_EOS:
        /* TODO 
         * Empty the adapter
         */
        ret = gst_pad_push_event(dmaienc->srcpad, event);
        break;
    case GST_EVENT_FLUSH_START:
        /* Flush the adapter */
        gst_adapter_clear(dmaienc->adapter);
        /* Flush the encoder */
        if (encoder->eops->codec_flush) {
            encoder->eops->codec_flush(dmaienc);
        }

        ret = gst_pad_push_event(dmaienc->srcpad, event);
        break;
    default:
        ret = gst_pad_push_event(dmaienc->srcpad, event);
    }

    gst_object_unref(dmaienc);
    return ret;
}

void release_cb(gpointer data, GstTIDmaiBufferTransport *buf){
    GstTIDmaienc *dmaienc = (GstTIDmaienc *)data;
    gint spos = Buffer_getUserPtr(GST_TIDMAIBUFFERTRANSPORT_DMAIBUF(buf)) -
        Buffer_getUserPtr(dmaienc->outBuf);
    gint buffer_size = Buffer_getNumBytesUsed(GST_TIDMAIBUFFERTRANSPORT_DMAIBUF(buf));
    gint epos = spos + buffer_size;
    struct cmemSlice *slice, *nslice;
    GList *e;

    if (!epos > dmaienc->outBufSize){
        GST_ELEMENT_ERROR(dmaienc,RESOURCE,NO_SPACE_LEFT,(NULL),
            ("Releasing buffer how ends outside memory boundaries"));
        return;
    }

    GST_DEBUG("Releasing memory from %d to %d",spos,epos);
    g_mutex_lock(dmaienc->freeMutex);
    e = dmaienc->freeSlices;

    /* Merge free memory */
    while (e){
        slice = (struct cmemSlice *)e->data;
        
        /* Are we contigous to this block? */
        if (slice->start == epos){
            GST_DEBUG("Merging free buffer at beggining free block (%d,%d)",
                slice->start,slice->end);
            /* Merge with current block*/
            slice->start -= buffer_size;
            slice->size += buffer_size;
            /* Merge with previous block? */
            if (g_list_previous(e)){
                nslice = (struct cmemSlice *)g_list_previous(e)->data;
                if (nslice->end == slice->start){
                    GST_DEBUG("Closing gaps...");
                    nslice->end += slice->size;
                    nslice->size += slice->size;
                    g_free(slice);
                    dmaienc->freeSlices = 
                        g_list_delete_link(dmaienc->freeSlices,e);
                }
            }
            g_mutex_unlock(dmaienc->freeMutex);
            return;
        }
        if (slice->end == spos){
            GST_DEBUG("Merging free buffer at end of free block (%d,%d)",
                slice->start,slice->end);
            /* Merge with current block*/
            slice->end += buffer_size;
            slice->size += buffer_size;
            /* Merge with next block? */
            if (g_list_next(e)){
                nslice = (struct cmemSlice *)g_list_next(e)->data;
                if (nslice->start == slice->end){
                    GST_DEBUG("Closing gaps...");
                    slice->end += nslice->size;
                    slice->size += nslice->size;
                    g_free(nslice);
                    dmaienc->freeSlices = 
                        g_list_delete_link(dmaienc->freeSlices,g_list_next(e));
                }
            }
            g_mutex_unlock(dmaienc->freeMutex);
            return;
        }
        /* Create a new free slice */
        if (slice->start > epos){
            GST_DEBUG("Creating new free slice %d,%d before %d,%d",spos,epos,
                slice->start,slice->end);
            nslice = g_malloc0(sizeof(struct cmemSlice));
            nslice->start = spos;
            nslice->end = epos;
            nslice->size = buffer_size;
            dmaienc->freeSlices = g_list_insert_before(dmaienc->freeSlices,e,
                nslice);
            g_mutex_unlock(dmaienc->freeMutex);
            return;
        }
        
        e = g_list_next(e);
    }

    GST_DEBUG("Creating new free slice %d,%d at end of list",spos,epos);
    /* We reach the end of the list, so we append the free slice at the 
       end
     */
    nslice = g_malloc0(sizeof(struct cmemSlice));
    nslice->start = spos;
    nslice->end = epos;
    nslice->size = buffer_size;
    dmaienc->freeSlices = g_list_insert_before(dmaienc->freeSlices,NULL,
        nslice);
    g_mutex_unlock(dmaienc->freeMutex);
}

GList *sliceAvailable(GstTIDmaienc *dmaienc, gint size){
    GList *e;
    struct cmemSlice *slice;
    
    /* Find free memory */
    GST_DEBUG("Finding free memory");
    g_mutex_lock(dmaienc->freeMutex);
    e = dmaienc->freeSlices;
    while (e){
        slice = (struct cmemSlice *)e->data;
        GST_DEBUG("Evaluating free slice from %d to %d",slice->start,slice->end);
        if (slice->size >= size){
            /* We mark all the memory as buffer at this point
             * to avoid merges while we are using the area
             * Once we know how much memory we actually used, we 
             * update to the real memory size that was used
             */
            slice->start += size;
            slice->size -= size;
            g_mutex_unlock(dmaienc->freeMutex);
            return e;
        }

        e = g_list_next(e);
    }    
    g_mutex_unlock(dmaienc->freeMutex);
    GST_DEBUG("Free memory not found...");
    
    return NULL;
}

Buffer_Handle encode_buffer_get_free(GstTIDmaienc *dmaienc, GList **e){
    Buffer_Attrs  Attrs  = Buffer_Attrs_DEFAULT;
    Buffer_Handle hBuf;
    struct cmemSlice *slice;
    gint offset;

    Attrs.reference = TRUE;
    /* Find free buffer */
    *e = sliceAvailable(dmaienc,dmaienc->singleOutBufSize);
    if (!*e){
        GST_ELEMENT_ERROR(dmaienc,STREAM,FAILED,(NULL),
           	("Not enough space free on the output buffer"));
        return NULL;
    }
    slice = (struct cmemSlice *)((*e)->data);
    /* The offset was already reserved, so we need to correct the start */
    offset = slice->start - dmaienc->singleOutBufSize;

    hBuf = Buffer_create(dmaienc->inBufSize,&Attrs);
    GST_DEBUG("Creating buffer at offset %d",offset);
    Buffer_setUserPtr(hBuf,Buffer_getUserPtr(dmaienc->outBuf) + offset);
    Buffer_setNumBytesUsed(hBuf,dmaienc->singleOutBufSize);
    Buffer_setSize(hBuf,dmaienc->singleOutBufSize);

    return hBuf;
}

/* Return a dmai buffer from the passed gstreamer buffer */
Buffer_Handle get_raw_buffer(GstTIDmaienc *dmaienc, GstBuffer *buf){
    GstTIDmaiencClass      *gclass;
    GstTIDmaiencData       *encoder;

    gclass = (GstTIDmaiencClass *) (G_OBJECT_GET_CLASS (dmaienc));
    encoder = (GstTIDmaiencData *)
       g_type_get_qdata(G_OBJECT_CLASS_TYPE(gclass),GST_TIDMAIENC_PARAMS_QDATA);

    if (GST_IS_TIDMAIBUFFERTRANSPORT(buf)){
        switch (encoder->eops->codec_type) {
            case VIDEO:
            case IMAGE: 
                if (Buffer_getType(GST_TIDMAIBUFFERTRANSPORT_DMAIBUF(buf))
                    == Buffer_Type_GRAPHICS){
                    /* Easy: we got a gfx buffer from upstream */
                    return GST_TIDMAIBUFFERTRANSPORT_DMAIBUF(buf);
                } else {
                    /* Still easy: got a DMAI transport, just not of gfx type... */
                    Buffer_Handle hBuf;
                    BufferGfx_Attrs gfxAttrs    = BufferGfx_Attrs_DEFAULT;

                    gfxAttrs.bAttrs.reference   = TRUE;
                    gfxAttrs.dim.width          = dmaienc->width;
                    gfxAttrs.dim.height         = dmaienc->height;
                    gfxAttrs.colorSpace         = dmaienc->colorSpace;
                    gfxAttrs.dim.lineLength     = BufferGfx_calcLineLength(dmaienc->width,
                                                    dmaienc->colorSpace);

                    hBuf = Buffer_create(dmaienc->inBufSize, &gfxAttrs.bAttrs);
                    Buffer_setUserPtr(hBuf,
                        Buffer_getUserPtr(GST_TIDMAIBUFFERTRANSPORT_DMAIBUF(buf)));
                    Buffer_setNumBytesUsed(hBuf,dmaienc->inBufSize);
                    Buffer_setSize(hBuf,dmaienc->inBufSize);

                    return hBuf;
                }
                break;
            default:
                return GST_TIDMAIBUFFERTRANSPORT_DMAIBUF(buf);
        }
    } else {
        BufferGfx_Attrs gfxAttrs    = BufferGfx_Attrs_DEFAULT;
        Buffer_Attrs Attrs    = Buffer_Attrs_DEFAULT;
        Buffer_Attrs *attrs;

        switch (encoder->eops->codec_type) {
            case VIDEO:
            case IMAGE: 
                /* Slow path: Copy the data into gfx buffer */

                gfxAttrs.dim.width          = dmaienc->width;
                gfxAttrs.dim.height         = dmaienc->height;
                gfxAttrs.colorSpace         = dmaienc->colorSpace;
                gfxAttrs.dim.lineLength     = BufferGfx_calcLineLength(dmaienc->width,
                                                dmaienc->colorSpace);

                attrs = &gfxAttrs.bAttrs;
                break;
            default:
                attrs= &Attrs;
        }
        /* Allocate a Buffer tab and copy the data there */
        if (!dmaienc->inBuf){
            dmaienc->inBuf = Buffer_create(dmaienc->inBufSize,attrs);

            if (dmaienc->inBuf == NULL) {
                GST_ELEMENT_ERROR(dmaienc,RESOURCE,NO_SPACE_LEFT,(NULL),
                    ("failed to create input buffers"));
                return NULL;
            }

            GST_DEBUG("Input buffer handler: %p\n",dmaienc->inBuf);
        }

        memcpy(Buffer_getUserPtr(dmaienc->inBuf),GST_BUFFER_DATA(buf),
                dmaienc->inBufSize);

        Buffer_setNumBytesUsed(dmaienc->inBuf,dmaienc->inBufSize);

        return dmaienc->inBuf;
    }
}

/******************************************************************************
 * encode
 *  This function encodes a frame and push the buffer downstream
 ******************************************************************************/
static int encode(GstTIDmaienc *dmaienc,GstBuffer * rawData){
    GstTIDmaiencClass      *gclass;
    GstTIDmaiencData       *encoder;
    Buffer_Handle  hDstBuf,hSrcBuf;
    GstBuffer     *outBuf;
    GList *element;
    gint unused;
    struct cmemSlice *slice;
    int ret = -1;

    gclass = (GstTIDmaiencClass *) (G_OBJECT_GET_CLASS (dmaienc));
    encoder = (GstTIDmaiencData *)
       g_type_get_qdata(G_OBJECT_CLASS_TYPE(gclass),GST_TIDMAIENC_PARAMS_QDATA);

    /* Obtain a free output buffer for the decoded data */
    hSrcBuf = get_raw_buffer(dmaienc,rawData);
    hDstBuf = encode_buffer_get_free(dmaienc,&element);

    if (!hSrcBuf || !hDstBuf){
        goto failure;
    }
    slice = (struct cmemSlice *)element->data;

    if (!encoder->eops->codec_process(dmaienc,hSrcBuf,hDstBuf)){
        goto failure;
    }

    /* Create a DMAI transport buffer object to carry a DMAI buffer to
     * the source pad.  The transport buffer knows how to release the
     * buffer for re-use in this element when the source pad calls
     * gst_buffer_unref().
         */
    outBuf = gst_tidmaibuffertransport_new(hDstBuf,NULL, NULL);
    GST_BUFFER_SIZE(outBuf) = Buffer_getNumBytesUsed(hDstBuf);

    /* Do a 32 byte aligment on the circular buffer, otherwise
       the DSP may corrupt data.
     */
    Buffer_setNumBytesUsed(hDstBuf,(Buffer_getNumBytesUsed(hDstBuf) & ~0x1f)
                                    + 0x20);
    g_mutex_lock(dmaienc->freeMutex);
    /* Return unused memory */
    unused = dmaienc->singleOutBufSize - Buffer_getNumBytesUsed(hDstBuf);
    slice->start -= unused;
    slice->size += unused;
    if (slice->size == 0){
        g_free(slice);
        dmaienc->freeSlices = g_list_delete_link (dmaienc->freeSlices,element);
    }
    g_mutex_unlock(dmaienc->freeMutex);

    gst_tidmaibuffertransport_set_release_callback(
        (GstTIDmaiBufferTransport *)outBuf,release_cb,dmaienc);

    if (dmaienc->firstBuffer) {
        dmaienc->firstBuffer = FALSE;
        if (encoder->stream_ops && encoder->stream_ops->generate_codec_data){
            GstBuffer *codec_data =
                encoder->stream_ops->generate_codec_data(dmaienc,outBuf);
            if (codec_data){
                GstCaps *caps = gst_caps_make_writable(
                    gst_caps_ref (GST_PAD_CAPS(dmaienc->srcpad)));
                GST_INFO("Setting codec_data on the caps");
                gst_caps_set_simple (caps, "codec_data",
                    GST_TYPE_BUFFER, codec_data, (char *)NULL);
                gst_pad_set_caps(dmaienc->srcpad,caps);
                gst_buffer_unref (codec_data);
            } else {
                GST_WARNING("no codec_data generated");
            }
        }
    }

    /* Pickup the frame type in a variable, the transform function below may need it */
    dmaienc->lastFrameType = gstti_bufferGFX_getFrameType(hSrcBuf);

    /* If this stream needs any kind of transformation, this is the right time */
    if (encoder->stream_ops && encoder->stream_ops->transform){
        outBuf = encoder->stream_ops->transform(dmaienc,outBuf);
        if (!outBuf){
            GST_ELEMENT_ERROR(dmaienc,STREAM,FAILED,(NULL),
                ("Failed to perform buffer transform"));
        }
    }
    
    gst_buffer_copy_metadata(outBuf,rawData,
        GST_BUFFER_COPY_FLAGS | GST_BUFFER_COPY_TIMESTAMPS);

	ret = (int)Buffer_getNumBytesUsed(hSrcBuf);

	if (encoder->eops->codec_type == VIDEO
                || encoder->eops->codec_type == IMAGE) {
	    /* DMAI set the buffer type on the input buffer, since only this one
	     * is a GFX buffer
	     */
	    if (dmaienc->lastFrameType == dmaienc->keyFrameType){
	        GST_BUFFER_FLAG_UNSET(outBuf, GST_BUFFER_FLAG_DELTA_UNIT);
	    } else {
	        GST_BUFFER_FLAG_SET(outBuf, GST_BUFFER_FLAG_DELTA_UNIT);
	    }
	    /* Lets help the qtmuxer, since it doesn't like buffers with only 
	     * timestamps
	     */
	    if (!GST_CLOCK_TIME_IS_VALID(GST_BUFFER_DURATION(outBuf))) {
	        GST_BUFFER_DURATION(outBuf) = dmaienc->averageDuration;
	    }
	} else if (encoder->eops->codec_type == AUDIO) {
		GST_BUFFER_DURATION(outBuf) = (ret / dmaienc->asampleSize)
			* dmaienc->asampleTime;
	}

    /* We must release the buffer structure if we aren't
       going to release it later
     */
    if (!((GST_IS_TIDMAIBUFFERTRANSPORT (rawData) &&
           GST_TIDMAIBUFFERTRANSPORT_DMAIBUF(rawData) == hSrcBuf) 
          ||
          (hSrcBuf == dmaienc->inBuf)
         )){
        Buffer_delete(hSrcBuf);
        hSrcBuf = NULL;
    }
    gst_buffer_unref(rawData);
    rawData = NULL;

	/* The transform function may have already created an non DMAI output 
	 * buffer, so we have to check to avoid doing a memcpy twice.
	 */
    if (dmaienc->copyOutput && GST_IS_TIDMAIBUFFERTRANSPORT(outBuf)) {
        GstBuffer *buf = gst_buffer_copy(outBuf);
        gst_buffer_unref(outBuf);
        outBuf = buf;
    }

    gst_buffer_set_caps(outBuf, GST_PAD_CAPS(dmaienc->srcpad));
    if (gst_pad_push(dmaienc->srcpad, outBuf) != GST_FLOW_OK) {
        GST_WARNING_OBJECT(dmaienc,"Failed to push to pad buffer");
    }

failure:
    if (rawData != NULL)
        gst_buffer_unref(rawData);

    return ret;
}

static GstBuffer *adapter_get_buffer(GstTIDmaienc *dmaienc,
					GstTIDmaiencData *encoder){
	GstBuffer *buf = NULL;
	const guint8 *buffer = NULL;

    if (encoder->eops->codec_type == AUDIO){
    	buffer = gst_adapter_peek(dmaienc->adapter,dmaienc->inBufSize);
		buf = gst_buffer_new();
		GST_BUFFER_DATA(buf) = (guint8 *)buffer;
		GST_BUFFER_SIZE(buf) = dmaienc->inBufSize;
		GST_BUFFER_TIMESTAMP(buf) = dmaienc->basets;
		GST_BUFFER_DURATION(buf) = (dmaienc->inBufSize / dmaienc->asampleSize)
			* dmaienc->asampleTime;
    } else {
    	/* For Video processing we want to use gst_adapter_take_buffer
    	 * because it keeps the timestamps
    	 */
      	buf = gst_adapter_take_buffer(dmaienc->adapter,dmaienc->inBufSize);
    }

    return buf;
}

/******************************************************************************
 * gst_tidmaienc_chain
 *    This is the main processing routine.  This function receives a buffer
 *    from the sink pad, and pass it to the parser, who is responsible to either
 *    buffer them until it has a full frame. If the parser returns a full frame
 *    we push a gsttidmaibuffer to the encoder function.
 ******************************************************************************/
static GstFlowReturn gst_tidmaienc_chain(GstPad * pad, GstBuffer * buf)
{
    GstTIDmaienc *dmaienc = (GstTIDmaienc *)GST_OBJECT_PARENT(pad);
    GstTIDmaiencClass *gclass;
    GstTIDmaiencData *encoder;
    int bytesConsumed;

    gclass = (GstTIDmaiencClass *) (G_OBJECT_GET_CLASS (dmaienc));
    encoder = (GstTIDmaiencData *)
       g_type_get_qdata(G_OBJECT_CLASS_TYPE(gclass),GST_TIDMAIENC_PARAMS_QDATA);

    if (!GST_IS_TIDMAIBUFFERTRANSPORT(buf) ||
        Buffer_getType(GST_TIDMAIBUFFERTRANSPORT_DMAIBUF(buf))
          != Buffer_Type_GRAPHICS){

        if (!GST_CLOCK_TIME_IS_VALID(dmaienc->basets)){
            dmaienc->basets = GST_BUFFER_TIMESTAMP(buf);
        }

        /* Push the buffer into the adapter*/
        gst_adapter_push(dmaienc->adapter,buf);

        if (gst_adapter_available(dmaienc->adapter) >= dmaienc->inBufSize){
			buf = adapter_get_buffer(dmaienc,encoder);
        } else {
        	buf = NULL;
        }
    } else {
        GST_DEBUG("Using accelerated buffer\n");
    }

    while (buf){
    	bytesConsumed = encode(dmaienc, buf);
		buf = NULL;

       	if (bytesConsumed < 0) {
        	GST_ELEMENT_ERROR(dmaienc,STREAM,FAILED,(NULL),
            	("Failed to encode buffer"));
           	gst_buffer_unref(buf);
        	return GST_FLOW_UNEXPECTED;
        }

    	if (encoder->eops->codec_type == AUDIO) {
       		/* Need to flush the adapter */
       		gst_adapter_flush(dmaienc->adapter,bytesConsumed);
			if (gst_adapter_available(dmaienc->adapter) == 0) {
				dmaienc->basets = GST_CLOCK_TIME_NONE;
			} else {
	       		dmaienc->basets += (bytesConsumed / dmaienc->asampleSize)
					* dmaienc->asampleTime;
			}

			if (gst_adapter_available(dmaienc->adapter) >= dmaienc->inBufSize){
				buf = adapter_get_buffer(dmaienc,encoder);
			}
       	}
    }

    return GST_FLOW_OK;
}


/******************************************************************************
 * Custom ViM Settings for editing this file
 ******************************************************************************/
#if 0
 Tabs (use 4 spaces for indentation)
 vim:set tabstop=4:      /* Use 4 spaces for tabs          */
 vim:set shiftwidth=4:   /* Use 4 spaces for >> operations */
 vim:set expandtab:      /* Expand tabs into white spaces  */
#endif
