/*
 * gsttiauddec.c
 *
 * This file defines the "TIAuddec" element, which decodes an xDM 0.9 audio
 * stream.
 *
 * Example usage:
 *     gst-launch filesrc location=<audio file> !
 *         TIAuddec engineName="<engine name>" codecName="<codecName>" !
 *         fakesink silent=TRUE
 *
 * Notes:
 *  * If the upstream element (i.e. demuxer or typefind element) negotiates
 *    caps with TIAuddec, the engineName and codecName properties will be
 *    auto-detected based on the mime type requested.  The engine and codec
 *    names used for particular mime types are defined in gsttiauddec.h.
 *    Currently, they are set to use the engine and codec names provided with
 *    the TI evaluation codecs.
 *  * This element currently assumes that the codec produces RAW output.
 *
 * Original Author:
 *     Don Darling, Texas Instruments, Inc.
 *
 * Contributions by:
 *     Diego Dompe, RidgeRun
 *
 * Copyright (C) $year Texas Instruments Incorporated - http://www.ti.com/
 * Copyright (C) 2009 RidgeRun
 *
 * This program is free software; you can redistribute it and/or modify 
 * it under the terms of the GNU Lesser General Public License as
 * published by the Free Software Foundation version 2.1 of the License.
 *
 * This program is distributed #as is# WITHOUT ANY WARRANTY of any kind,
 * whether express or implied; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 */

#ifdef HAVE_CONFIG_H
#  include <config.h>
#endif

#include <stdio.h>
#include <string.h>
#include <gst/gst.h>

#include <pthread.h>

#include <ti/sdo/dmai/Dmai.h>
#include <ti/sdo/dmai/Buffer.h>
#include <ti/sdo/dmai/ce/Adec.h>

#include "gsttiauddec.h"
#include "gsttidmaibuffertransport.h"
#include "gstticodecs.h"
#include "gsttithreadprops.h"
#include "gsttiquicktime_aac.h"

/* Declare variable used to categorize GST_LOG output */
GST_DEBUG_CATEGORY_STATIC (gst_tiauddec_debug);
#define GST_CAT_DEFAULT gst_tiauddec_debug

/* Element property identifiers */
enum
{
  PROP_0,
  PROP_ENGINE_NAME,     /* engineName     (string)  */
  PROP_CODEC_NAME,      /* codecName      (string)  */
  PROP_NUM_OUTPUT_BUFS, /* numOutputBufs  (int)     */
  PROP_DISPLAY_BUFFER,  /* displayBuffer  (boolean) */
  PROP_GEN_TIMESTAMPS   /* genTimeStamps  (boolean) */
};

/* Define sink (input) pad capabilities.  Currently, AAC and MP3 are
 * supported.
 */
static GstStaticPadTemplate sink_factory = GST_STATIC_PAD_TEMPLATE(
    "sink",
    GST_PAD_SINK,
    GST_PAD_ALWAYS,
    GST_STATIC_CAPS
    ("audio/mpeg, "
        "mpegversion = (int) { 1, 4 }")
);

/* Define source (output) pad capabilities.  Currently, RAW is supported. */
static GstStaticPadTemplate src_factory = GST_STATIC_PAD_TEMPLATE(
    "src",
    GST_PAD_SRC,
    GST_PAD_ALWAYS,
    GST_STATIC_CAPS
    ("audio/x-raw-int, "
        "endianness = (int) " G_STRINGIFY (G_BYTE_ORDER) ", "
        "signed = (boolean)true, "
        "width = (int) 16, depth = (int) 16, "
        "rate = (int) {8000, 11025, 12000, 16000, 22050, 24000, 32000, 44100, 48000 }, "
        "channels = (int) [ 1, 2 ]")
);


/* Declare a global pointer to our element base class */
static GstElementClass *parent_class = NULL;

/* Static Function Declarations */
static void
 gst_tiauddec_base_init(gpointer g_class);
static void
 gst_tiauddec_class_init(GstTIAuddecClass *g_class);
static void
 gst_tiauddec_init(GstTIAuddec *object, GstTIAuddecClass *g_class);
static void
 gst_tiauddec_set_property (GObject *object, guint prop_id,
     const GValue *value, GParamSpec *pspec);
static void
 gst_tiauddec_get_property (GObject *object, guint prop_id, GValue *value,
     GParamSpec *pspec);
static gboolean
 gst_tiauddec_set_sink_caps(GstPad *pad, GstCaps *caps);
static gboolean
 gst_tiauddec_set_source_caps(GstPad *pad, gint sampleRate);
static gboolean
 gst_tiauddec_sink_event(GstPad *pad, GstEvent *event);
static GstFlowReturn
 gst_tiauddec_chain(GstPad *pad, GstBuffer *buf);
static gboolean
 gst_tiauddec_init_audio(GstTIAuddec *auddec);
static gboolean
 gst_tiauddec_exit_audio(GstTIAuddec *auddec);
static GstStateChangeReturn
 gst_tiauddec_change_state(GstElement *element, GstStateChange transition);
static void*
 gst_tiauddec_decode_thread(void *arg);
static void*
 gst_tiauddec_queue_thread(void *arg);
static void
 gst_tiauddec_broadcast_queue_thread(GstTIAuddec *auddec);
static void
 gst_tiauddec_wait_on_queue_thread(GstTIAuddec *auddec, Int32 waitQueueSize);
static void
 gst_tiauddec_drain_pipeline(GstTIAuddec *auddec);
static gboolean 
    gst_tiauddec_codec_start (GstTIAuddec  *auddec);
static gboolean 
    gst_tiauddec_codec_stop (GstTIAuddec  *auddec);

/******************************************************************************
 * gst_tiauddec_class_init_trampoline
 *    Boiler-plate function auto-generated by "make_element" script.
 ******************************************************************************/
static void gst_tiauddec_class_init_trampoline(gpointer g_class, gpointer data)
{
    parent_class = (GstElementClass*) g_type_class_peek_parent(g_class);
    gst_tiauddec_class_init((GstTIAuddecClass*)g_class);
}


/******************************************************************************
 * gst_tiauddec_get_type
 *    Boiler-plate function auto-generated by "make_element" script.
 *    Defines function pointers for initialization routines for this element.
 ******************************************************************************/
GType gst_tiauddec_get_type(void)
{
    static GType object_type = 0;

    if (G_UNLIKELY(object_type == 0)) {
        static const GTypeInfo object_info = {
            sizeof(GstTIAuddecClass),
            gst_tiauddec_base_init,
            NULL,
            gst_tiauddec_class_init_trampoline,
            NULL,
            NULL,
            sizeof(GstTIAuddec),
            0,
            (GInstanceInitFunc) gst_tiauddec_init
        };

        object_type = g_type_register_static((gst_element_get_type()),
                          "GstTIAuddec", &object_info, (GTypeFlags)0);

        /* Initialize GST_LOG for this object */
        GST_DEBUG_CATEGORY_INIT(gst_tiauddec_debug, "TIAuddec", 0,
            "TI xDM 0.9 Audio Decoder");

        GST_LOG("initialized get_type\n");

    }

    return object_type;
};


/******************************************************************************
 * gst_tiauddec_base_init
 *    Boiler-plate function auto-generated by "make_element" script.
 *    Initializes element base class.
 ******************************************************************************/
static void gst_tiauddec_base_init(gpointer gclass)
{
    static GstElementDetails element_details = {
        "TI xDM 0.9 Audio Decoder",
        "Codec/Decoder/Audio",
        "Decodes audio using an xDM 0.9-based codec",
        "Don Darling; Texas Instruments, Inc."
    };

    GstElementClass *element_class = GST_ELEMENT_CLASS(gclass);

    gst_element_class_add_pad_template(element_class,
        gst_static_pad_template_get (&src_factory));
    gst_element_class_add_pad_template(element_class,
        gst_static_pad_template_get (&sink_factory));
    gst_element_class_set_details(element_class, &element_details);

}


/******************************************************************************
 * gst_tiauddec_class_init
 *    Boiler-plate function auto-generated by "make_element" script.
 *    Initializes the TIAuddec class.
 ******************************************************************************/
static void gst_tiauddec_class_init(GstTIAuddecClass *klass)
{
    GObjectClass    *gobject_class;
    GstElementClass *gstelement_class;

    gobject_class    = (GObjectClass*)    klass;
    gstelement_class = (GstElementClass*) klass;

    gobject_class->set_property = gst_tiauddec_set_property;
    gobject_class->get_property = gst_tiauddec_get_property;

    gstelement_class->change_state = gst_tiauddec_change_state;

    g_object_class_install_property(gobject_class, PROP_ENGINE_NAME,
        g_param_spec_string("engineName", "Engine Name",
            "Engine name used by Codec Engine", "unspecified",
            G_PARAM_READWRITE));

    g_object_class_install_property(gobject_class, PROP_CODEC_NAME,
        g_param_spec_string("codecName", "Codec Name", "Name of audio codec",
            "unspecified", G_PARAM_READWRITE));

    g_object_class_install_property(gobject_class, PROP_NUM_OUTPUT_BUFS,
        g_param_spec_int("numOutputBufs",
            "Number of Ouput Buffers",
            "Number of output buffers to allocate for codec",
            2, G_MAXINT32, 2, G_PARAM_WRITABLE));

    g_object_class_install_property(gobject_class, PROP_DISPLAY_BUFFER,
        g_param_spec_boolean("displayBuffer", "Display Buffer",
            "Display circular buffer status while processing",
            FALSE, G_PARAM_WRITABLE));

    g_object_class_install_property(gobject_class, PROP_GEN_TIMESTAMPS,
        g_param_spec_boolean("genTimeStamps", "Generate Time Stamps",
            "Set timestamps on output buffers",
            TRUE, G_PARAM_WRITABLE));
}


/******************************************************************************
 * gst_tiauddec_init
 *    Initializes a new element instance, instantiates pads and sets the pad
 *    callback functions.
 ******************************************************************************/
static void gst_tiauddec_init(GstTIAuddec *auddec, GstTIAuddecClass *gclass)
{
    /* Instantiate encoded audio sink pad.
     *
     * Fixate on our static template caps instead of writing a getcaps
     * function, which is overkill for this element.
     */
    auddec->sinkpad =
        gst_pad_new_from_static_template(&sink_factory, "sink");
    gst_pad_set_setcaps_function(
        auddec->sinkpad, GST_DEBUG_FUNCPTR(gst_tiauddec_set_sink_caps));
    gst_pad_set_event_function(
        auddec->sinkpad, GST_DEBUG_FUNCPTR(gst_tiauddec_sink_event));
    gst_pad_set_chain_function(
        auddec->sinkpad, GST_DEBUG_FUNCPTR(gst_tiauddec_chain));
    gst_pad_fixate_caps(auddec->sinkpad,
        gst_caps_make_writable(
            gst_caps_copy(gst_pad_get_pad_template_caps(auddec->sinkpad))));

    /* Instantiate deceoded audio source pad */
    auddec->srcpad =
        gst_pad_new_from_static_template(&src_factory, "src");
    gst_pad_fixate_caps(auddec->srcpad,
        gst_caps_make_writable(
            gst_caps_copy(gst_pad_get_pad_template_caps(auddec->srcpad))));

    /* Add pads to TIAuddec element */
    gst_element_add_pad(GST_ELEMENT(auddec), auddec->sinkpad);
    gst_element_add_pad(GST_ELEMENT(auddec), auddec->srcpad);

    /* Initialize TIAuddec state */
    auddec->engineName          = NULL;
    auddec->codecName           = NULL;
    auddec->displayBuffer       = FALSE;
    auddec->genTimeStamps       = TRUE;

    auddec->hEngine             = NULL;
    auddec->hAd                 = NULL;
    auddec->channels            = 0;
    auddec->drainingEOS         = FALSE;
    auddec->threadStatus        = 0UL;

    auddec->decodeDrained       = FALSE;
    auddec->waitOnDecodeDrain   = NULL;

    auddec->hInFifo             = NULL;

    auddec->waitOnQueueThread   = NULL;
    auddec->waitQueueSize       = 0;

    auddec->waitOnDecodeThread  = NULL;

    auddec->waitQueueSize       = 0;
    auddec->numOutputBufs       = 0UL;
    auddec->hOutBufTab          = NULL;
    auddec->circBuf             = NULL;

    auddec->aac_header_data     = NULL;
}


/******************************************************************************
 * gst_tiauddec_set_property
 *     Set element properties when requested.
 ******************************************************************************/
static void gst_tiauddec_set_property(GObject *object, guint prop_id,
                const GValue *value, GParamSpec *pspec)
{
    GstTIAuddec *auddec = GST_TIAUDDEC(object);

    GST_LOG("begin set_property\n");

    switch (prop_id) {
        case PROP_ENGINE_NAME:
            if (auddec->engineName) {
                g_free((gpointer)auddec->engineName);
            }
            auddec->engineName =
                (gchar*)g_malloc(strlen(g_value_get_string(value)) + 1);
            strcpy((gchar *)auddec->engineName, g_value_get_string(value));
            GST_LOG("setting \"engineName\" to \"%s\"\n", auddec->engineName);
            break;
        case PROP_CODEC_NAME:
            if (auddec->codecName) {
                g_free((gpointer)auddec->codecName);
            }
            auddec->codecName =
                (gchar*)g_malloc(strlen(g_value_get_string(value)) + 1);
            strcpy((gchar*)auddec->codecName, g_value_get_string(value));
            GST_LOG("setting \"codecName\" to \"%s\"\n", auddec->codecName);
            break;
        case PROP_NUM_OUTPUT_BUFS:
            auddec->numOutputBufs = g_value_get_int(value);
            GST_LOG("setting \"numOutputBufs\" to \"%ld\"\n",
                auddec->numOutputBufs);
            break;
        case PROP_DISPLAY_BUFFER:
            auddec->displayBuffer = g_value_get_boolean(value);
            GST_LOG("setting \"displayBuffer\" to \"%s\"\n",
                auddec->displayBuffer ? "TRUE" : "FALSE");
            break;
        case PROP_GEN_TIMESTAMPS:
            auddec->genTimeStamps = g_value_get_boolean(value);
            GST_LOG("setting \"genTimeStamps\" to \"%s\"\n",
                auddec->genTimeStamps ? "TRUE" : "FALSE");
            break;
        default:
            G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);
            break;
    }

    GST_LOG("end set_property\n");
}

/******************************************************************************
 * gst_tiauddec_get_property
 *     Return values for requested element property.
 ******************************************************************************/
static void gst_tiauddec_get_property(GObject *object, guint prop_id,
                GValue *value, GParamSpec *pspec)
{
    GstTIAuddec *auddec = GST_TIAUDDEC(object);

    GST_LOG("begin get_property\n");

    switch (prop_id) {
        case PROP_ENGINE_NAME:
            g_value_set_string(value, auddec->engineName);
            break;
        case PROP_CODEC_NAME:
            g_value_set_string(value, auddec->codecName);
            break;
        default:
            G_OBJECT_WARN_INVALID_PROPERTY_ID(object, prop_id, pspec);
            break;
    }

    GST_LOG("end get_property\n");
}


/******************************************************************************
 * gst_tiauddec_set_sink_caps
 *     Negotiate our sink pad capabilities.
 ******************************************************************************/
static gboolean gst_tiauddec_set_sink_caps(GstPad *pad, GstCaps *caps)
{
    GstTIAuddec  *auddec;
    GstStructure *capStruct;
    const gchar  *mime;
    char         *string;
    GstTICodec   *codec = NULL;
    gint rate;

    auddec    = GST_TIAUDDEC(gst_pad_get_parent(pad));
    capStruct = gst_caps_get_structure(caps, 0);
    mime      = gst_structure_get_name(capStruct);

    string = gst_caps_to_string(caps);
    GST_INFO("requested sink caps:  %s", string);
    g_free(string);

    /* Generic Audio Properties */
    if (!strncmp(mime, "audio/", 6)) {

        if (!gst_structure_get_int(capStruct, "rate", &rate)) {
            rate = 0;
        }

        if (!gst_structure_get_int(capStruct, "channels", &auddec->channels)) {
            /* Default to 2 channels if not specified */
            auddec->channels = 2;
        }
    }

    /* MPEG Audio */
    if (!strcmp(mime, "audio/mpeg")) {
        gint bitrate;
        gint mpegversion;
        gint layer;

        if (!gst_structure_get_int(capStruct, "bitrate", &bitrate)) {
            bitrate = 0;
        }

        if (!gst_structure_get_int(capStruct, "mpegversion", &mpegversion)) {
            mpegversion = 0;
        }

        if (!gst_structure_get_int(capStruct, "layer", &layer)) {
            /* Default to layer 2 if not specified */
            layer = 2;
        }

        /* Use MP3 Decoder for MPEG1 Layer 2 */
        if (mpegversion == 1 && layer == 2) {
            codec = gst_ticodec_get_codec("MPEG1L2 Audio Decoder");
        }

        /* Use MP3 Decoder for MP3 */
        else if (mpegversion == 1 && layer == 3) {
            codec = gst_ticodec_get_codec("MPEG1L3 Audio Decoder");
        }

        /* Use AAC Decoder for MPEG4 */
        else if (mpegversion == 4) {
            codec = gst_ticodec_get_codec("AAC Audio Decoder");
            auddec->aac_header_data = gst_aac_header_create(rate, 
                            auddec->channels);
        }

        /* MPEG version not supported */
        else {
            GST_ERROR("MPEG version not supported");
            gst_object_unref(auddec);
            return FALSE;
        }
    }

    /* Mime type not supported */
    else {
        GST_ERROR("stream type not supported");
        gst_object_unref(auddec);
        return FALSE;
    }

    /* Report if the required codec was not found */
    if (!codec) {
        GST_ERROR("unable to find codec needed for stream");
        gst_object_unref(auddec);
        return FALSE;
    }

    /* Shut-down any running audio decoder */
    if (!gst_tiauddec_exit_audio(auddec)) {
        gst_object_unref(auddec);
        return FALSE;
    }

    /* Configure the element to use the detected engine name and codec, unless
     * they have been using the set_property function.
     */
    if (!auddec->engineName) {
        auddec->engineName = codec->CE_EngineName;
    }
    if (!auddec->codecName) {
        auddec->codecName = codec->CE_CodecName;
    }

    gst_object_unref(auddec);

    GST_LOG("sink caps negotiation successful\n");
    return TRUE;
}


/******************************************************************************
 * gst_tiauddec_set_source_caps
 *     Negotiate our source pad capabilities.
 ******************************************************************************/
static gboolean gst_tiauddec_set_source_caps(GstPad *pad, gint sampleRate)
{
    GstCaps  *caps;
    gboolean  ret;
    char     *string;

    caps =
        gst_caps_new_simple ("audio/x-raw-int",
            "endianness", G_TYPE_INT,     G_BYTE_ORDER,
            "signed",     G_TYPE_BOOLEAN, TRUE,
            "width",      G_TYPE_INT,     16,
            "depth",      G_TYPE_INT,     16,
            "rate",       G_TYPE_INT,     sampleRate,
            "channels",   G_TYPE_INT,     2,
            NULL);

    /* Set the source pad caps */
    string = gst_caps_to_string(caps);
    GST_LOG("setting source caps to RAW:  %s", string);
    g_free(string);

    if (!gst_pad_set_caps(pad, caps)) {
        ret = FALSE;
    }
    gst_caps_unref(caps);

    return ret;
}


/******************************************************************************
 * gst_tiauddec_sink_event
 *     Perform event processing on the input stream.  At the moment, this
 *     function isn't needed as this element doesn't currently perform any
 *     specialized event processing.  We'll leave it in for now in case we need
 *     it later on.
 ******************************************************************************/
static gboolean gst_tiauddec_sink_event(GstPad *pad, GstEvent *event)
{
    GstTIAuddec *auddec;
    gboolean     ret;

    auddec = GST_TIAUDDEC(GST_OBJECT_PARENT(pad));

    GST_DEBUG("pad \"%s\" received:  %s\n", GST_PAD_NAME(pad),
        GST_EVENT_TYPE_NAME(event));

    switch (GST_EVENT_TYPE(event)) {

        case GST_EVENT_NEWSEGMENT:
            /* maybe save and/or update the current segment (e.g. for output
             * clipping) or convert the event into one in a different format
             * (e.g. BYTES to TIME) or drop it and set a flag to send a
             * newsegment event in a different format later
             */
            ret = gst_pad_push_event(auddec->srcpad, event);
            break;

        case GST_EVENT_EOS:
            /* end-of-stream: process any remaining encoded frame data */
            GST_LOG("no more input; draining remaining encoded audio data\n");
            if (!auddec->drainingEOS) {
               gst_tiauddec_drain_pipeline(auddec);
            }

            /* Propagate EOS to downstream elements */
            ret = gst_pad_push_event(auddec->srcpad, event);
            break;

        case GST_EVENT_FLUSH_STOP:
            ret = gst_pad_push_event(auddec->srcpad, event);
            break;

        /* Unhandled events */
        case GST_EVENT_BUFFERSIZE:
        case GST_EVENT_CUSTOM_BOTH:
        case GST_EVENT_CUSTOM_BOTH_OOB:
        case GST_EVENT_CUSTOM_DOWNSTREAM:
        case GST_EVENT_CUSTOM_DOWNSTREAM_OOB:
        case GST_EVENT_CUSTOM_UPSTREAM:
        case GST_EVENT_FLUSH_START:
        case GST_EVENT_NAVIGATION:
        case GST_EVENT_QOS:
        case GST_EVENT_SEEK:
        case GST_EVENT_TAG:
        default:
            ret = gst_pad_event_default(pad, event);
            break;

    }

    return ret;

}

/******************************************************************************
 * gst_tiauddec_chain
 *    This is the main processing routine.  This function receives a buffer
 *    from the sink pad, processes it, and pushes the result to the source
 *    pad.
 ******************************************************************************/
static GstFlowReturn gst_tiauddec_chain(GstPad * pad, GstBuffer * buf)
{
    GstTIAuddec *auddec = GST_TIAUDDEC(GST_OBJECT_PARENT(pad));
    gboolean     checkResult;

    /* If any thread aborted, communicate it to the pipeline */
    if (gst_tithread_check_status(auddec, TIThread_ANY_ABORTED, checkResult)) {
       gst_buffer_unref(buf);
       return GST_FLOW_UNEXPECTED;
    }

    /* If our engine handle is currently NULL, then either this is our first
     * buffer or the upstream element has re-negotiated our capabilities which
     * resulted in our engine being closed.  In either case, we need to
     * initialize (or re-initialize) our audio decoder to handle the new
     * stream.
     */
    if (auddec->hEngine == NULL) {
        if (!gst_tiauddec_init_audio(auddec)) {
            GST_ERROR("unable to initialize audio\n");
            gst_buffer_unref(buf);
            return GST_FLOW_UNEXPECTED;
        }

        /* If we are decoding aac stream, then check whether stream has valid
         * ADIF or ADTS header. If not, then add ADIF header. This header is
         * created by reading parsing codec_data field passed via demuxer.
         *
         * Note: This is used when qtdemuxer is used for playing mp4 files.
         */
        if (auddec->aac_header_data) {

            if (!gst_aac_valid_header(GST_BUFFER_DATA(buf))) {

                GST_LOG("Adding auto-generated ADIF header.\n");

                /* Queue up the aac header data into a circular buffer */
                if (Fifo_put(auddec->hInFifo, auddec->aac_header_data) < 0) {
                    GST_ERROR("Failed to send buffer to queue thread\n");
                    gst_buffer_unref(buf);
                    return GST_FLOW_UNEXPECTED;
                }
            }
        }
   
        GST_TICIRCBUFFER_TIMESTAMP(auddec->circBuf) =
            GST_CLOCK_TIME_IS_VALID(GST_BUFFER_TIMESTAMP(buf)) ?
            GST_BUFFER_TIMESTAMP(buf) : 0ULL;
    }

    /* Don't queue up too many buffers -- if we collect too many input buffers
     * without consuming them we'll run out of memory.  Once we reach a
     * threshold, block until the queue thread removes some buffers.
     */
    Rendezvous_reset(auddec->waitOnQueueThread);
    if (Fifo_getNumEntries(auddec->hInFifo) > 2000) {
        gst_tiauddec_wait_on_queue_thread(auddec, 1800);
    }

    /* Queue up the encoded data stream into a circular buffer */
    if (Fifo_put(auddec->hInFifo, buf) < 0) {
        GST_ERROR("Failed to send buffer to queue thread\n");
        gst_buffer_unref(buf);
        return GST_FLOW_UNEXPECTED;
    }

    return GST_FLOW_OK;
}


/******************************************************************************
 * gst_tiauddec_init_audio
 *     Initialize or re-initializes the audio stream
 ******************************************************************************/
static gboolean gst_tiauddec_init_audio(GstTIAuddec * auddec)
{
    Rendezvous_Attrs      rzvAttrs  = Rendezvous_Attrs_DEFAULT;
    struct sched_param    schedParam;
    pthread_attr_t        attr;
    Fifo_Attrs            fAttrs    = Fifo_Attrs_DEFAULT;

    GST_LOG("begin init_audio\n");

    /* If audio has already been initialized, shut down previous decoder */
    if (auddec->hEngine) {
        if (!gst_tiauddec_exit_audio(auddec)) {
            GST_ERROR("failed to shut down existing audio decoder\n");
            return FALSE;
        }
    }

    /* Make sure we know what codec we're using */
    if (!auddec->engineName) {
        GST_ERROR("engine name not specified\n");
        return FALSE;
    }

    if (!auddec->codecName) {
        GST_ERROR("codec name not specified\n");
        return FALSE;
    }

    /* Set up the queue fifo */
    auddec->hInFifo = Fifo_create(&fAttrs);

    /* Initialize thread status management */
    auddec->threadStatus = 0UL;
    pthread_mutex_init(&auddec->threadStatusMutex, NULL);

    /* Initialize rendezvous objects for making threads wait on conditions */
    auddec->waitOnDecodeDrain   = Rendezvous_create(100, &rzvAttrs);
    auddec->waitOnQueueThread   = Rendezvous_create(100, &rzvAttrs);
    auddec->waitOnDecodeThread  = Rendezvous_create(2, &rzvAttrs);
    auddec->drainingEOS         = FALSE;

    /* Initialize the custom thread attributes */
    if (pthread_attr_init(&attr)) {
        GST_WARNING("failed to initialize thread attrs\n");
        gst_tiauddec_exit_audio(auddec);
        return FALSE;
    }

    /* Force the thread to use the system scope */
    if (pthread_attr_setscope(&attr, PTHREAD_SCOPE_SYSTEM)) {
        GST_WARNING("failed to set scope attribute\n");
        gst_tiauddec_exit_audio(auddec);
        return FALSE;
    }

    /* Force the thread to use custom scheduling attributes */
    if (pthread_attr_setinheritsched(&attr, PTHREAD_EXPLICIT_SCHED)) {
        GST_WARNING("failed to set schedule inheritance attribute\n");
        gst_tiauddec_exit_audio(auddec);
        return FALSE;
    }

    /* Set the thread to be fifo real time scheduled */
    if (pthread_attr_setschedpolicy(&attr, SCHED_FIFO)) {
        GST_WARNING("failed to set FIFO scheduling policy\n");
        gst_tiauddec_exit_audio(auddec);
        return FALSE;
    }

    /* Set the display thread priority */
    schedParam.sched_priority = GstTIAudioThreadPriority;
    if (pthread_attr_setschedparam(&attr, &schedParam)) {
        GST_WARNING("failed to set scheduler parameters\n");
        return FALSE;
    }

    /* Create decoder thread */
    if (pthread_create(&auddec->decodeThread, &attr,
            gst_tiauddec_decode_thread, (void*)auddec)) {
        GST_ERROR("failed to create decode thread\n");
        gst_tiauddec_exit_audio(auddec);
        return FALSE;
    }
    gst_tithread_set_status(auddec, TIThread_DECODE_CREATED);

    /* Wait for decoder thread to finish initilization before creating queue
     * thread.
     */
    Rendezvous_meet(auddec->waitOnDecodeThread);

    /* Make sure circular buffer and display buffer handles are created by
     * decoder thread.
     */
    if (auddec->circBuf == NULL || auddec->hOutBufTab == NULL) {
        GST_ERROR("decode thread failed to create circbuf or display buffer"
                  " handles\n");
        return FALSE;
    }

    /* Create queue thread */
    if (pthread_create(&auddec->queueThread, NULL,
            gst_tiauddec_queue_thread, (void*)auddec)) {
        GST_ERROR("failed to create queue thread\n");
        gst_tiauddec_exit_audio(auddec);
        return FALSE;
    }
    gst_tithread_set_status(auddec, TIThread_QUEUE_CREATED);

    GST_LOG("end init_audio\n");
    return TRUE;
}


/******************************************************************************
 * gst_tiauddec_exit_audio
 *    Shut down any running audio decoder, and reset the element state.
 ******************************************************************************/
static gboolean gst_tiauddec_exit_audio(GstTIAuddec *auddec)
{
    gboolean checkResult;
    void*    thread_ret;

    GST_LOG("begin exit_audio\n");

    /* Drain the pipeline if it hasn't already been drained */
    if (!auddec->drainingEOS) {
       gst_tiauddec_drain_pipeline(auddec);
     }

    /* Shut down the decode thread */
    if (gst_tithread_check_status(
            auddec, TIThread_DECODE_CREATED, checkResult)) {
        GST_LOG("shutting down decode thread\n");

        if (pthread_join(auddec->decodeThread, &thread_ret) == 0) {
            if (thread_ret == GstTIThreadFailure) {
                GST_DEBUG("decode thread exited with an error condition\n");
            }
        }
    }

    /* Shut down the queue thread */
    if (gst_tithread_check_status(
            auddec, TIThread_QUEUE_CREATED, checkResult)) {
        GST_LOG("shutting down queue thread\n");

        /* Unstop the queue thread if needed, and wait for it to finish */
        Fifo_flush(auddec->hInFifo);

        if (pthread_join(auddec->queueThread, &thread_ret) == 0) {
            if (thread_ret == GstTIThreadFailure) {
                GST_DEBUG("queue thread exited with an error condition\n");
            }
        }
    }

    /* Shut down thread status management */
    auddec->threadStatus = 0UL;
    pthread_mutex_destroy(&auddec->threadStatusMutex);

    /* Shut down any remaining items */
    if (auddec->hInFifo) {
        Fifo_delete(auddec->hInFifo);
        auddec->hInFifo = NULL;
    }

    if (auddec->waitOnQueueThread) {
        Rendezvous_delete(auddec->waitOnQueueThread);
        auddec->waitOnQueueThread = NULL;
    }

    if (auddec->waitOnDecodeThread) {
        Rendezvous_delete(auddec->waitOnDecodeThread);
        auddec->waitOnDecodeThread = NULL;
    }

    if (auddec->waitOnDecodeDrain) {
        Rendezvous_delete(auddec->waitOnDecodeDrain);
        auddec->waitOnDecodeDrain = NULL;
    }

    if (auddec->circBuf) {
        GST_LOG("freeing cicrular input buffer\n");
        gst_ticircbuffer_unref(auddec->circBuf);
        auddec->circBuf       = NULL;
    }

    if (auddec->hOutBufTab) {
        GST_LOG("freeing output buffer\n");
        BufTab_delete(auddec->hOutBufTab);
        auddec->hOutBufTab = NULL;
    }

    GST_LOG("end exit_audio\n");
    return TRUE;
}


/******************************************************************************
 * gst_tiauddec_change_state
 *     Manage state changes for the audio stream.  The gStreamer documentation
 *     states that state changes must be handled in this manner:
 *        1) Handle ramp-up states
 *        2) Pass state change to base class
 *        3) Handle ramp-down states
 ******************************************************************************/
static GstStateChangeReturn gst_tiauddec_change_state(GstElement *element,
                                GstStateChange transition)
{
    GstStateChangeReturn  ret    = GST_STATE_CHANGE_SUCCESS;
    GstTIAuddec          *auddec = GST_TIAUDDEC(element);

    GST_LOG("begin change_state (%d)\n", transition);

    /* Handle ramp-up state changes */
    switch (transition) {
        case GST_STATE_CHANGE_NULL_TO_READY:
            break;
        default:
            break;
    }

    /* Pass state changes to base class */
    ret = GST_ELEMENT_CLASS(parent_class)->change_state(element, transition);
    if (ret == GST_STATE_CHANGE_FAILURE)
        return ret;

    /* Handle ramp-down state changes */
    switch (transition) {
        case GST_STATE_CHANGE_READY_TO_NULL:
            /* Shut down any running audio decoder */
            if (!gst_tiauddec_exit_audio(auddec)) {
                return GST_STATE_CHANGE_FAILURE;
            }
            break;

        default:
            break;
    }

    GST_LOG("end change_state\n");
    return ret;
}


/******************************************************************************
 * gst_tiauddec_codec_stop
 *     Release codec engine resources
 *****************************************************************************/
static gboolean gst_tiauddec_codec_stop (GstTIAuddec  *auddec)
{
    if (auddec->hAd) {
        GST_LOG("closing audio decoder\n");
        Adec_delete(auddec->hAd);
        auddec->hAd = NULL;
    }

    if (auddec->hEngine) {
        GST_LOG("closing codec engine\n");
        Engine_close(auddec->hEngine);
        auddec->hEngine = NULL;
    }

    return TRUE;
}


/******************************************************************************
 * gst_tiauddec_codec_start
 *     Initialize codec engine
 *****************************************************************************/
static gboolean gst_tiauddec_codec_start (GstTIAuddec  *auddec)
{
    AUDDEC_Params         params    = Adec_Params_DEFAULT;
    AUDDEC_DynamicParams  dynParams = Adec_DynamicParams_DEFAULT;
    Buffer_Attrs          bAttrs    = Buffer_Attrs_DEFAULT;

    /* Open the codec engine */
    GST_LOG("opening codec engine \"%s\"\n", auddec->engineName);
    auddec->hEngine = Engine_open((Char *) auddec->engineName, NULL, NULL);

    if (auddec->hEngine == NULL) {
        GST_ERROR("failed to open codec engine \"%s\"\n", auddec->engineName);
        return FALSE;
    }

    /* Initialize audio decoder */
    GST_LOG("opening audio decoder \"%s\"\n", auddec->codecName);
    auddec->hAd = Adec_create(auddec->hEngine, (Char*)auddec->codecName,
                      &params, &dynParams);

    if (auddec->hAd == NULL) {
        GST_ERROR("failed to create audio decoder: %s\n", auddec->codecName);
        GST_LOG("closing codec engine\n");
        return FALSE;
    }

    /* Set up a circular input buffer capable of holding two encoded frames */
    auddec->circBuf =
        gst_ticircbuffer_new(Adec_getInBufSize(auddec->hAd) * 10, 3, FALSE);

    if (auddec->circBuf == NULL) {
        GST_ERROR("failed to create circular input buffer\n");
        return FALSE;
    }

    /* Display buffer contents if displayBuffer=TRUE was specified */
    gst_ticircbuffer_set_display(auddec->circBuf, auddec->displayBuffer);

    /* Define the number of display buffers to allocate.  This number must be
     * at least 2, If this has not been set via set_property(), default to the
     * minimal value.
     */
    if (auddec->numOutputBufs == 0) {
        auddec->numOutputBufs = 2;
    }
    /* Create codec output buffers.  
     */
    GST_LOG("creating output buffers\n");

    bAttrs.useMask = gst_tidmaibuffertransport_GST_FREE;

    auddec->hOutBufTab =
        BufTab_create(auddec->numOutputBufs, Adec_getOutBufSize(auddec->hAd), 
            &bAttrs);

    if (auddec->hOutBufTab == NULL) {
        GST_ERROR("failed to create output buffer\n");
        return FALSE;
    }

    return TRUE;
}

/******************************************************************************
 * gst_tiauddec_decode_thread
 *     Call the audio codec to process a full input buffer
 ******************************************************************************/
static void* gst_tiauddec_decode_thread(void *arg)
{
    GstTIAuddec   *auddec    = GST_TIAUDDEC(gst_object_ref(arg));
    void          *threadRet = GstTIThreadSuccess;
    Buffer_Handle  hDstBuf;
    Int32          encDataConsumed;
    GstBuffer     *encDataWindow = NULL;
    GstClockTime   encDataTime;
    Buffer_Handle  hEncDataWindow;
    GstBuffer     *outBuf;
    Int            ret;
    guint          sampleDataSize;
    GstClockTime   sampleDuration;
    guint          sampleRate;

    GST_LOG("starting auddec decode thread\n");

    /* Initialize codec engine */
    ret = gst_tiauddec_codec_start(auddec);

    /* Notify main thread if it is waiting to create queue thread */
    Rendezvous_meet(auddec->waitOnDecodeThread);

    if (ret == FALSE) {
        GST_ERROR("failed to start codec\n");
        goto thread_exit;
    }

    while (TRUE) {

        /* Obtain an encoded data frame */
        encDataWindow  = gst_ticircbuffer_get_data(auddec->circBuf);
        encDataTime    = GST_BUFFER_TIMESTAMP(encDataWindow);
        hEncDataWindow = GST_TIDMAIBUFFERTRANSPORT_DMAIBUF(encDataWindow);

        if (GST_BUFFER_SIZE(encDataWindow) == 0) {
            GST_LOG("no audio data remains\n");
            if (!auddec->drainingEOS) {
                goto thread_failure;
            }
            goto thread_exit;
        }

        /* Obtain a free output buffer for the decoded data */
        hDstBuf = BufTab_getFreeBuf(auddec->hOutBufTab);
        if (hDstBuf == NULL) {
            GST_ERROR("failed to get a free contiguous buffer from BufTab\n");
            goto thread_failure;
        }

        /* Invoke the audio decoder */
        GST_LOG("Invoking the audio decoder at 0x%08lx with %u bytes\n",
            (unsigned long)Buffer_getUserPtr(hEncDataWindow),
            GST_BUFFER_SIZE(encDataWindow));
        ret             = Adec_process(auddec->hAd, hEncDataWindow, hDstBuf);
        encDataConsumed = Buffer_getNumBytesUsed(hEncDataWindow);

        if (ret < 0) {
            GST_ERROR("failed to decode audio buffer\n");
            goto thread_failure;
        }

        /* If no encoded data was used we cannot find the next frame */
        if (ret == Dmai_EBITERROR && encDataConsumed == 0) {
            GST_ERROR("fatal bit error\n");
            goto thread_failure;
        }

        if (ret > 0) {
            GST_LOG("Adec_process returned success code %d\n", ret); 
        }

        /* DMAI currently doesn't provide a way to retrieve the number of
         * samples decoded or the duration of the decoded audio data.  For
         * now, derive the duration from the number of bytes decoded by the
         * codec.
         */
        sampleDataSize = Buffer_getNumBytesUsed(hDstBuf);
        sampleRate     = Adec_getSampleRate(auddec->hAd);
        sampleDuration = (GstClockTime)
            (((gdouble)(sampleDataSize) / (gdouble)auddec->channels /
              (gdouble) 2 / (gdouble)sampleRate)
            * GST_SECOND);

        /* Release the reference buffer, and tell the circular buffer how much
         * data was consumed.
         */
        ret = gst_ticircbuffer_data_consumed(auddec->circBuf, encDataWindow,
                  encDataConsumed);
        encDataWindow = NULL;

        if (!ret) {
            goto thread_failure;
        }

        /* Set the source pad capabilities based on the decoded frame
         * properties.
         */
        gst_tiauddec_set_source_caps(
            auddec->srcpad, Adec_getSampleRate(auddec->hAd));

        /* Create a DMAI transport buffer object to carry a DMAI buffer to
         * the source pad.  The transport buffer knows how to release the
         * buffer for re-use in this element when the source pad calls
         * gst_buffer_unref().
         */
        outBuf = gst_tidmaibuffertransport_new(hDstBuf);
        gst_buffer_set_data(outBuf, GST_BUFFER_DATA(outBuf),
            Buffer_getNumBytesUsed(hDstBuf));
        gst_buffer_set_caps(outBuf, GST_PAD_CAPS(auddec->srcpad));

        /* If we have a valid time stamp, set it on the buffer */
        if (auddec->genTimeStamps && GST_CLOCK_TIME_IS_VALID(encDataTime)) {
            GST_LOG("audio timestamp value: %llu\n", encDataTime);
            GST_BUFFER_TIMESTAMP(outBuf) = encDataTime;
            GST_BUFFER_DURATION(outBuf)  = sampleDuration;
        }
        else {
            GST_BUFFER_TIMESTAMP(outBuf) = GST_CLOCK_TIME_NONE;
        }

        /* Tell circular buffer how much time we consumed */
        gst_ticircbuffer_time_consumed(auddec->circBuf, sampleDuration);

        /* Push the transport buffer to the source pad */
        GST_LOG("pushing buffer to source pad\n");

        if (gst_pad_push(auddec->srcpad, outBuf) != GST_FLOW_OK) {
            GST_DEBUG("push to source pad failed\n");
            goto thread_failure;
        }
    }

thread_failure:

    /* If encDataWindow is non-NULL, something bad happened before we had a
     * chance to release it.  Release it now so we don't block the pipeline.
     * We release it by telling the circular buffer that we're done with it and
     * consumed no data.
     */
    if (encDataWindow) {
        gst_ticircbuffer_data_consumed(auddec->circBuf, encDataWindow, 0);
    }

    gst_tithread_set_status(auddec, TIThread_DECODE_ABORTED);
    threadRet = GstTIThreadFailure;
    gst_ticircbuffer_consumer_aborted(auddec->circBuf);
    Rendezvous_force(auddec->waitOnQueueThread);

thread_exit:
 
    /* Stop codec engine */
    if (gst_tiauddec_codec_stop(auddec) < 0) {
        GST_ERROR("failed to stop codec\n");
    }

    /* Notify main thread if it is waiting on decode thread shut-down */
    auddec->decodeDrained = TRUE;
    Rendezvous_force(auddec->waitOnDecodeDrain);

    gst_object_unref(auddec);

    GST_LOG("exit audio decode_thread (%d)\n", (int)threadRet);
    return threadRet;
}


/******************************************************************************
 * gst_tiauddec_queue_thread 
 *     Add an input buffer to the circular buffer            
 ******************************************************************************/
static void* gst_tiauddec_queue_thread(void *arg)
{
    GstTIAuddec* auddec    = GST_TIAUDDEC(gst_object_ref(arg));
    void*        threadRet = GstTIThreadSuccess;
    GstBuffer*   encData;
    Int          fifoRet;

    while (TRUE) {

        /* Get the next input buffer (or block until one is ready) */
        fifoRet = Fifo_get(auddec->hInFifo, &encData);

        if (fifoRet < 0) {
            GST_ERROR("failed to get buffer from audio thread\n");
            goto thread_failure;
        }

        /* Did the audio thread flush the fifo? */
        if (fifoRet == Dmai_EFLUSH) {
            goto thread_exit;
        }

        /* Send the buffer to the circular buffer */
        if (!gst_ticircbuffer_queue_data(auddec->circBuf, encData)) {
            goto thread_failure;
        }

        /* Release the buffer we received from the sink pad */
        gst_buffer_unref(encData);

        /* If we've reached the EOS, start draining the circular buffer when
         * there are no more buffers in the FIFO.
         */ 
        if (auddec->drainingEOS && Fifo_getNumEntries(auddec->hInFifo) == 0) {
            gst_ticircbuffer_drain(auddec->circBuf, TRUE);
        }   

        /* Unblock any pending puts to our Fifo if we have reached our
         * minimum threshold.
         */
        gst_tiauddec_broadcast_queue_thread(auddec);
    }

thread_failure:
    gst_tithread_set_status(auddec, TIThread_QUEUE_ABORTED);
    threadRet = GstTIThreadFailure;

thread_exit:
    gst_object_unref(auddec);
    return threadRet;
}


/******************************************************************************
 * gst_tiauddec_wait_on_queue_thread
 *    Wait for the queuethread to process data
 ******************************************************************************/
static void gst_tiauddec_wait_on_queue_thread(GstTIAuddec *auddec,
                Int32 waitQueueSize)
{
    auddec->waitQueueSize = waitQueueSize;
    Rendezvous_meet(auddec->waitOnQueueThread);
}


/******************************************************************************
 * gst_tiauddec_broadcast_queue_thread
 *    Broadcast when the queue thread has processed enough buffers from the
 *    fifo to unblock anyone waiting to queue some more.
 ******************************************************************************/
static void gst_tiauddec_broadcast_queue_thread(GstTIAuddec *auddec)
{
    if (auddec->waitQueueSize < Fifo_getNumEntries(auddec->hInFifo)) {
          return;
    } 
    Rendezvous_force(auddec->waitOnQueueThread);
}


/******************************************************************************
 * gst_tiauddec_drain_pipeline
 *    Push any remaining input buffers through the queue and decode threads
 ******************************************************************************/
static void gst_tiauddec_drain_pipeline(GstTIAuddec *auddec)
{
    gboolean checkResult;

    auddec->drainingEOS = TRUE;

    /* If the processing threads haven't been created, there is nothing to
     * drain.
     */
    if (!gst_tithread_check_status(
             auddec, TIThread_QUEUE_CREATED, checkResult)) {
        return;
    }
    if (!gst_tithread_check_status(
             auddec, TIThread_DECODE_CREATED, checkResult)) {
        return;
    }

    /* If the queue fifo still has entries in it, it will drain the
     * circular buffer once all input buffers have been added to the
     * circular buffer.  If the fifo is already empty, we must drain
     * the circular buffer here.
     */
    if (Fifo_getNumEntries(auddec->hInFifo) == 0) {
        gst_ticircbuffer_drain(auddec->circBuf, TRUE);
    }
    else {
        Rendezvous_force(auddec->waitOnQueueThread);
    }

    /* Wait for the decoder to drain */
    if (!auddec->decodeDrained) {
        Rendezvous_meet(auddec->waitOnDecodeDrain);
    }
    auddec->decodeDrained = FALSE;

}


/******************************************************************************
 * Custom ViM Settings for editing this file
 ******************************************************************************/
#if 0
 Tabs (use 4 spaces for indentation)
 vim:set tabstop=4:      /* Use 4 spaces for tabs          */
 vim:set shiftwidth=4:   /* Use 4 spaces for >> operations */
 vim:set expandtab:      /* Expand tabs into white spaces  */
#endif
